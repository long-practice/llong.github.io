---
title: 프로그래머스 인공지능 데브코스 46일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 10주차(22.2.14.(월) ~ 22.2.18.(토)) 
  선형회귀
  선형분류
  Weekly Mission
tags:
- 최적화
- 평균 제곱 오차(MSE)
- 교차 엔트로피(Cross Entropy)
- 소프트맥스 함수
- 음의 로그우도
- 데이터 전처리
- 정규화
- 가중치 초기화
- 대칭적 가중치
- 난수로 가중치 초기화
- 탄력(가속도, 관성)
- 네스테로프 가속 경사도 관성
- 적응적 학습률
- AdaGrad
- RMSProp
- Adam
- ResNet 구현
- Residual block

use_math: True
---
# 46일차(신경망 기초 - Deep Learning 최적화)

10주차(22.2.14.(월) ~ 22.2.18.(금)): CNN & RNN
* Deep Learning 기초
* CNN Models
* Deep Learning 최적화
* RNN
* weekly mission

### 기계학습의 최적화
- 훈련집합으로 학습을 마친 후, 현장에서 발생하는 새로운 샘플을 잘 예측해야 함 $\rightarrow$ 일반화 능력이 좋아야 함
- 훈련집합은 전체 데이터의 대리자 역할이고, 검증집합은 테스트 집합의 대리자 역할
- MSE, 로그 우도함수 등의 손실함수는 주어진 과업의 학습 성능의 대리자 역할

#### 최적화가 어려운 이유
- 대리자 관계(전체를 알지 못하기 때문)
- 매개탐색 공간에서 목적함수의 비볼록 성질(복잡한 함수), 고차원 특징 공간, 데이터의 희소성 등
- 긴 훈련 시간

### 평균 제곱 오차(MSE)
- 오차가 클수록 $e$값이 커지므로 벌점(정량적성능)으로 활용<br>
  $\displaystyle e=\frac{1}{2}\|\mathbf{y}-\mathbf{o}\|_{2}^{2}$<br>
<br>

#### 한계
- 더 많은 오류를 범한 상황이 더 낮은 벌점을 받은 꼴이 발생할 수 있다는 허점
- 즉, 학습이 더딘 부정적인 효과가 있음
- 예를 들어보면, 시그모이드 함수를 미분했을 때 $x$의 값이 커지게 되면 그 미분 값은 0에 가까워짐
- 따라서 $wx + b$의 값이 큰 값이 더 큰 오차를 범했음에도 불구하고 그레디언트 소멸 현상이 발생, 더 낮은 그레디언트를 얻음(낮은 벌점)<br>
<br>

---

### 교차 엔트로피(Cross Entropy)
#### 클래스가 2개일 경우
- 정답에 해당하는 $y$가 확률변수 (부류가 2개라고 가정하면 $y \in \{0, 1\}$)<br>
  $e=-\left(y \log _{2} o+(1-y) \log _{2}(1-o)\right)$<br>
  이 때 $o = \sigma(z)$이고, $z = wx + b$<br>
<br>

- 역할을 잘 수행했는지 확인해보면<br>
  1. 예측이 잘 된 경우($y = 1, o = 0.98$)<br>
     $e=-\left(1 \log _{2} 0.98+(1-1) \log _{2}(1-0.98)\right)=0.0291$로 낮은 값
  2. 예측이 잘 안된 경우($y = 1, o = 0.0001$)<br>
     $e=-\left(1 \log _{2} 0.0001+(1-1) \log _{2}(1-0.0001)\right)=13.2877$로 높은 값<br>
<br>
- 또한 공정한 벌점이 부여되는지 그레디언트를 확인해보면<br>
  $\displaystyle \frac{\partial e}{\partial w} = x(o - y)$과 $\displaystyle \frac{\partial e}{\partial b} = (o - y)$<br>
  그레디언트가 실제로 예측한 값과 실제 값의 차이에 비례하므로 그레디언트 소멸 현상을 방지할 수 있음<br>
  따라서 MSE의 더딘 학습 문제를 해결할 수 있음<br>
<br>
<br>

#### 클래스가 여러 개일 경우
- 출력 벡터 $\mathbf{o} = (o_1, o_2, \cdots, o_c)^T$인 상황으로 확장<br>
  $\displaystyle e=-\sum_{i=1, c}(y_{i} \log _{2} o_{i})$
- $y$가 3개의 클래스, $P(y) = (0, 0, 1)$이고 $Q(y) = (0.2, 0.3, 0.5)$일 때 교차 엔트로피는 $-\log(0.5)$

---

### 소프트맥스 함수
- 분류 결과 출력 값들이 확률 분포로써 나타내기 위해 사용<br>
  $\displaystyle O_{j}=\frac{e^{s_{j}}}{\sum_{i=1, c} e^{s_{i}}}$<br>
<br>
- 출력 노드의 계산 결과 $s_i^L$의 최댓값을 더욱 활성화(값이 1에 가깝도록), 다른 작은 값들은 억제 $\rightarrow$ 지수함수 사용의 이유
- 출력 값들을 모두 더하면 1이 되어 확률을 모방
- 클래스들 마다 확률의 상대 비교가 가능<br>
<br>
- 따라서 다중 로지스틱 회귀 분석 시 분류기의 최종 값을 확률로 표현(모방)하기 위해 적용
- 음의 로그우도(교차엔트로피를 적용하지만 정답 레이블이 one-hot 벡터임을 감안)를 목적함수로 사용

### 음의 로그우도 함수
- 모든 출력 노드값을 사용하나 MSE나 교차 엔트로피와 달리 $o_y$라는 하나의 노드만 적용<br>
  $e=-\log _{2} o_{y}$<br>
<br>
- 가령 소프트맥스 함수의 결과 값이 작다면, 즉, 해당분류로 클래스가 분류될 확률이 낮다면<br>
  출력값 $o$는 0에 가까워질 것이고 이에 따라 $e$는 한없이 커지게 될 것<br>
<br>
- 반면 출력 값이 크다면, 즉, 해당분류로 클래스가 분류될 확률이 높다면<br>
  $o$는 1에 가까워질 것이고 이에 따라 $e$는 0에 가까워질 것

### 소프트맥스 함수와 로그우도 함수
- 소프트맥스 함수는 **최댓값이 아닌 값을 억제**하여 0에 가깝게 만든다는 의도
- 신경망에 의한 **샘플의 정답에 해당하는 노드만 보겠다**는 로그우도와 잘 어울림
- **둘을 결합하여 사용**하는 경우가 많음

---

### 데이터 전처리 - 규모 문제
- 예를 들어 건강에 관련된 데이터(키(m), 몸무게(kg), 혈압)이 있을 때<br>
  각각의 데이터의 차이가 동일하다고 할 지라도 데이터를 처리하는 단위에 따라 특징 값의 차이가 바뀔 수 있음<br>
  즉, 키가 1.87(m)과 1.68(m)는 19cm 차이지만 특징 값 차이는 0.19인 반면<br>
  몸무게가 80(kg)과 50(kg)은 30kg 차이<br>
  <br>
  따라서 두 특징 값의 차이는 서로 대략 150배 차이가 나는 것을 확인할 수 있음<br>
  <br>
  
- 이 때, 그레디언트를 구해서 역전파 계산을 하면 키에 의한 영향보다 몸무게에 의한 영향이 압도적
- 즉, 키에 의한 학습 영향이 압도적으로 몸무게에 의한 학습 영향보다 적으므로 키에 의한 학습 속도가 더딜 수 밖에 없음
- 따라서 서로 다른 특징 값의 차이의 편차를 줄여줄 수 있도록 규모(단위)(scale)를 개선해야 함<br>
<br>
- 모든 특징들의 값이 양수이기 때문에 각각의 출력 값에 대한 그레디언트 값이 뭉치단위로 감소, 증가를 하게 됨<br>
- 즉, 가중치의 값들이 다 같이 감소되거나 증가되는 양상을 보임
- 따라서 최저점을 찾아가는 경로가 갈팡질팡하여 느리게 수렴

#### 정규화
- 평균 값이 0이 되도록, 극단 값들이 없도록 데이터 값들을 전처리
- 규모 문제와 양수 문제를 해결
- 특징별 독립적으로 적용
- 통계학의 정규 분포를 활용한 표준화 변환<br>
  $\displaystyle x_i^{new} = \frac{x_i^{old} - \mu_i}{\sigma_i}$
- 최대, 최소 변환을 적용한 경우<br>
  $\displaystyle x_i^{new} = \frac{x_i^{old} - \text{min}(x_i)}{\text{max}(x_i) - \text{min}(x_i)}$

#### 명목 변수를 one-hot 벡터로 변환
- 명목 변수: 객체간 서로 구분하기 위한 변수
- 명목 변수는 거리 개념, 수치 개념이 없음, 단순히 객체와 객체, 항목과 항목을 분류하기 위한 변수
- one-hot 벡터는 값의 개수만큼 비트를 부여
- 예를 들어 성별이라고 하는 특징 값을 (0, 1) $\rightarrow$ (남자, 여자), 체질이라고 하는 특징 값을 (0, 0, 1, 0) $\rightarrow$ (태양인, 태음인, 소양인, 소음인)

---

### 가중치 초기화 - 대칭적 가중치 문제
- 그레디언트는 $\delta_jz_i$
- 아래 그림을 살펴보면 입력이 동일할 때($z_1^{l - 1} = z_2^{l - 1}$) $l - 1$층 이후로는 $u_{11}^l$과 $u_{12}^l$는 같은 값으로 갱신
- 따라서 두 노드가 같은 일을 하는 중복 발생

![1.png](attachment:1.png)

#### 난수로 가중치 초기화
- 가우시안 또는 균일 분포에서 난수 추출 $\rightarrow$ 두 분포는 성능 차이 거의 없음
- 난수 범위는 $\displaystyle r=\frac{1}{\sqrt{n_{i n}}}$ 혹은 $\displaystyle r=\frac{\sqrt{6}}{\sqrt{n_{i n}+n_{\text {out }}}}$으로 $r$값을 결정하고 $[-r, r]$사이에서 난수를 발생<br>
  $n_{in}$은 노드로 들어오는 엣지 수, $n_{out}$은 노드에서 나가는 엣지 수<br>
<br>
- 편향은 보통 0으로 초기화<br>
<br>
- 사례<br>
  - AlexNet: 평균 0, 표준편차 0.01인 가우시안에서 난수 생성
  - ResNet: 평균 0, 표준편차 $\displaystyle \sqrt{\frac{2}{n_{in}}}$인 가우시안에서 난수 생성, 편향 0 설정
  
---

### 탄력(가속도, 관성)(momentum)
- 그레디언트 잡음 현상: 기계 학습은 훈련집합을 이용하여 매개변수의 경사도를 추정하므로 잡음 가능성 높음
- 탄력(가속도, 관성)은 경사도에 부드러움을 가하여 잡음 효과를 줄임
- 관성(가속도): 과거에 이동했던 방식을 기억하면서 기존 방향으로 일정 이상 추가 이동<br>
  $\rightarrow$ 지역 최저점, 안장점으로 가중치가 수렴 하는 문제 해소 $\rightarrow$ **수렴 속도 향상**
  
- 속도 벡터는 과거에 이동했던 속도와 현재의 그레디언트를 누적하여 계속 사용 $\rightarrow$ $\displaystyle \mathbf{v} = \alpha\mathbf{v} + \rho\frac{\partial J}{\partial \boldsymbol{\Theta}}$<br>
  이에 따라 그레디언트는 다음과 같이 갱신 $\boldsymbol{\Theta} = \boldsymbol{\Theta} - \mathbf{v}$
- 즉, 속도 벡터 $\mathbf{v}$는 이전 경사도를 누적한 것에 해당(처음 $\mathbf{v} = 0$로 출발)<br>
<br>
- $\alpha$(관성의 정도)가 0일 때 관성이 적용 안된 이전 경사도 갱신 공식과 동일
- $\alpha$가 1에 가까울수록 이전 경사도 정보에 큰 가중치를 주는 셈 $\rightarrow$ $\boldsymbol{\Theta}$가 그리는 궤적이 매끄러움
- 보통 $\alpha$값으로는 0.5, 0.9, 0.99 혹은 0.5로 시작하여 epoch가 지남에 따라 0.99에 도달하는 방법 사용<br>
<br>

#### 효과
- 지나침(overshooting) 현상을 누그러뜨림
- 값이 극적으로 바뀌는 것을 방지<br>
![2.png](attachment:2.png)

#### 네스테로프 가속 경사도 관성
- 현재 $\mathbf{v}$ 값으로 다음 이동할 곳 $\tilde{\boldsymbol{\Theta}}$을 예견하고, 예견한 곳의 경사도 $\displaystyle \left.\frac{\partial J}{\partial \boldsymbol{\Theta}}\right|_{\widetilde{\boldsymbol{\Theta}}}$를 사용(멈춤 용이)<br>
  $\tilde{\boldsymbol{\Theta}} = \boldsymbol{\Theta} - \alpha \mathbf{v}$<br>
  $\displaystyle \mathbf{v} = \alpha\mathbf{v} + \rho\left.\frac{\partial J}{\partial \boldsymbol{\Theta}}\right|_{\widetilde{\boldsymbol{\Theta}}}$<br>
  $\boldsymbol{\Theta} = \boldsymbol{\Theta} - \mathbf{v}$
  
---

### 적응적 학습률
- 학습률 $\rho$는 너무 크면 지나침(overshooting)에 따른 진자 현상, 너무 작으면 수렴이 느림<br>
![3.png](attachment:3.png)<br>

- 적응적 학습률: 경사도에 학습률 $\rho$를 곱하면, $\rho \frac{\partial J}{\partial \boldsymbol{\Theta}} = (\rho \frac{\partial J}{\partial \Theta_{1}}, \rho \frac{\partial J}{\partial \Theta_{2}}, \cdots, \rho \frac{\partial J}{\partial \Theta_{k}})^T$<br>
  기존 경사하강법은 모든 매개변수에 같은 크기의 학습률을 적용하지만 위 방식은 각각의 매개변수에 각기 다른 학습률 적용<br>
<br>
- 즉, 적응적 학습률은 매개변수마다 자신의 상황에 따라 학습룰 조절
- 학습률 담금질: 이전 경사도와 현재 경사도의 부호가 같은 매개변수는 값을 키우고 다른 매개변수는 값을 줄이는 전략<br>
<br>

#### AdaGrad
- 그레디언트 벡터 $\mathbf{g}$에 대해<br>
  $\mathbf{r} = \left(r_{1}, r_{2}, \cdots, r_{k}\right)^{\mathrm{T}}=\left(r_{1}+g_{1}^{2}, r_{2}+g_{2}^{2}, \cdots, r_{k}+g_{k}^{2}\right)^{\mathrm{T}}$<br>
  $\Delta \boldsymbol{\Theta} = \left(\Delta \theta_{1}, \Delta \theta_{2}, \cdots, \Delta \theta_{k}\right)^{\mathrm{T}}=\left(-\frac{\rho g_{1}}{\epsilon+\sqrt{r_{1}}},-\frac{\rho g_{2}}{\epsilon+\sqrt{r_{2}}}, \cdots,-\frac{\rho g_{k}}{\epsilon+\sqrt{r_{k}}}\right)^{\mathrm{T}}$<br>
  $\boldsymbol{\Theta} = \left(\theta_{1}, \theta_{2}, \cdots, \theta_{k}\right)^{\mathrm{T}}=\left(\theta_{1}+\Delta \theta_{1}, \theta_{2}+\Delta \theta_{2}, \cdots, \theta_{k}+\Delta \theta_{k}\right)^{\mathrm{T}}$<br>
  
- $\mathbf{r}$은 이전 경사도를 누적한 벡터<br>
  - $r_i$가 작으면 $\left\vert \Delta\theta_i \right\vert$는 커지기 때문에 많이 이동(초기 상태)
  - $r_i$가 크면 $\left\vert \Delta\theta_i \right\vert$는 작아지기 때문에 적게 이동(어느 정도 수렴의 방향이 정해지면 수렴 속도를 조절)<br>
<br>
- 따라서 $\displaystyle \frac{\rho}{\epsilon+\sqrt{r_{k}}}$은 상황에 따라 보폭을 정해주는 **적응적 학습률**로 볼 수 있음
- $\epsilon$은 분모가 0이 됨을 방지<br>
<br>
- 그런데 AdaGrad의 단점은 $\mathbf{r}$에 그레디언트의 제곱을 더함
- 따라서 오래된 경사도와 최근 경사도는 같은 비중의 역할을 수행
- $\mathbf{r}$이 점점 커져서 수렴을 방해할 가능성이 있음 $\rightarrow$ 현재 그레디언트 값이 중요한데 과거 그레디언트 값에 방해를 받을 가능성이 높음<br>
<br>

#### RMSProp
- 가중 이동 평균 기법을 적용<br>
  $\mathbf{r} = \alpha\mathbf{r} + (1 - \alpha)\mathbf{g} \odot \mathbf{g}$<br>
<br>
- $\alpha$가 작을수록 최근 것에 비중을 더 많이 둠
- 보통 $\alpha$로 0.9, 0.99, 0.999를 사용<br>
<br>

#### Adam
- RMSProp에 관성을 추가로 적용한 알고리즘<br>
  $\mathbf{v} = \alpha_1\mathbf{v} - (1 - \alpha_1)\mathbf{g}$<br>
  $\mathbf{r} = \alpha_2\mathbf{r} + (1 - \alpha_2)\mathbf{g} \odot \mathbf{g}$<br>
  <br>
  $\displaystyle\Delta\boldsymbol{\Theta} = -\frac{\rho}{\epsilon + \sqrt{\mathbf{r}}}\mathbf{v}$<br>
  $\boldsymbol{\Theta} = \boldsymbol{\Theta} + \Delta\boldsymbol{\Theta}$

---

### ResNet 구현

#### 라이브러리 호출


```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
```

---

#### Conv2d


```python
def conv3x3(in_channels, out_channels, stride = 1):
    return nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)
```

---

### Residual block


```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):
        super(ResidualBlock, self).__init__()
        self.conv1 = conv3x3(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace = True)
        self.conv2 = conv3x3(out_channels, out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        
    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out
        
    
        self.layer1 = self.make_layer(block, 16, layers[0])
        self.layer2 = self.make_layer(block, 32, layers[1], 2)
        self.layer3 = self.make_layer(block, 64, layers[2], 2)
        self.avg_pool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64, num_classes)
        
    def make_layer(self, block, out_channels, blocks, stride =1):
        downsample = None
        if (stride != 1) or (self.in_channels != out_channels):
            downsample = nn.Sequential(
                conv3x3(self.in_channels, out_channels, stride = stride),
                nn.BatchNorm2d(out_channels))
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for i in range(1, blocks):
            layers.append(block(out_channels, out_channels))
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.relu(out)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.avg_pool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out
```

---

#### ResNet


```python
class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=10):
        super(ResNet, self).__init__()
        self.in_channels = 16
        self.conv = conv3x3(3, 16)
        self.bn = nn.BatchNorm2d(16)
        self.relu = nn.ReLU(inplace = True)
        self.layer1 = self.make_layer(block, 16, layers[0])
        self.layer2 = self.make_layer(block, 32, layers[1], 2)
        self.layer3 = self.make_layer(block, 64, layers[2], 2)
        self.avg_pool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64, num_classes)
        
    def make_layer(self, block, out_channels, blocks, stride =1):
        downsample = None
        if (stride != 1) or (self.in_channels != out_channels):
            downsample = nn.Sequential(
                conv3x3(self.in_channels, out_channels, stride = stride),
                nn.BatchNorm2d(out_channels))
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for i in range(1, blocks):
            layers.append(block(out_channels, out_channels))
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = self.conv(x)
        out = self.bn(out)
        out = self.relu(out)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.avg_pool(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out
```

---

#### 모델 학습


```python
# Device configuration
# device = torch.device('cuda' if torch.cuda.s_available() else 'cpu')
# print(device)

num_epochs = 80
learning_rate = 0.001

transform = transforms.Compose([
    transforms.Pad(4),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32),
    transforms.ToTensor()
])
```

    cpu



```python
train_dataset = torchvision.datasets.CIFAR10(root='./dataset/',
                                             train=True,
                                             transform=transform,
                                             download=True)

test_dataset = torchvision.datasets.CIFAR10(root='./dataset/',
                                            train=False,
                                           transform=transforms.ToTensor())

# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=100,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=100,
                                          shuffle=False)
```

    Files already downloaded and verified



```python
model = ResNet(ResidualBlock, [2, 2, 2]).to('cuda')

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)
exp_lr_schedulter = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)
```

#### 모델 훈련, 모델 검증
이전 GoogLeNet 구현 시 작성했던 코드와 동일

---

### 느낀점
기존에 알고 있던 손실함수에 대한 내용과 더불어 가중치 초기화, 탄력(가속도, 관성), 적응적 학습률에 대해 알아보았다.<br>
과제를 했을 때 무심코 썼던 것들(adam, momentum, ...)들을 점차 알게되어가는 과정에서 깨달은 것들이 많이 있었다.<br>
하나하나 퍼즐을 맞춰가는 과정이 어렵고 힘들 수 있지만 무엇보다 퍼즐 조각을 영원히 잃어버리지 않는 노력도 필요하다고 생각한다<br>
나중에 모델을 구현할 때 응용하여 상황에 맞는 지표들을 사용할 수 있도록 반드시 복습을 하도록 하겠다
