---
title: 프로그래머스 인공지능 데브코스 55일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 12주차(22.2.28.(월) ~ 22.3.4.(금)) 
  데이터 팀에 관한 커리어 이야기
  빅데이터와 분산처리 시스템
  Hadoop과 Spark에 대한 이해
  Spark를 이용한 데이터 전처리 및 머신러닝 모델 설계
tags:
- 데이터 팀
- 데이터 팀의 목적
- 데이터 팀의 업무
- 데이터 인프라
- 데이터 웨어하우스
- ETL
- 데이터 팀의 구성원
- 데이터 분석
- 데이터 엔지니어
- 데이터 분석가
- 데이터 과학자
- 데이터 팀의 구조
- 중앙 집중 구조
- 분산 구조
- 하이브리드 구조
- 모델 개발 시 고려할 점

use_math: True
---

# 55일차(데이터 팀)

12주차(22.2.28.(월) ~ 22.3.4.(금)): 데이터 팀에 관한 내용, SPARK
* 데이터 팀의 역할
* 커리어 이야기
* SPARK
* SPARK 실습
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

<br>

### 데이터 팀에 관하여
#### 데이터 팀의 역할
- **신뢰할 수 있는 데이터를 바탕으로 부가가치 생성** <br>
<br>

#### 데이터 팀의 목표
- 고품질의 데이터를 제공하여 **정책 결정, 사용자의 서비스 경험**을 개선
- **결정과학**이라고도 부름. 즉, 데이터 참고 결정을 가능하게 함
- 데이터는 과거의 현상을 보여주는 역할. 따라서 데이터를 기반으로 미래의 선택을 결정하는 것은 굉장히 위험
- 머신러닝과 같은 데이터 기반 알고리즘을 통해 서비스를 개선(개인화를 바탕으로하는 추천 알고리즘 개선)<br>
  그러나 사람의 개입/도움이 반드시 필요 **(human-in-the-loop)**<br>
<br>

#### 데이터 팀의 업무<br>
- 데이터 인프라를 구축, 관리<br>
  - 데이터 인프라: 데이터 웨어하우스와 ETL(Extract, Transform, Load) 구성<br>
    - 데이터 웨어하우스: 데이터들을 저장하는 중앙 데이터베이스, 데이터 분석이 목적
    - ETL: 소스에 존재하는 데이터들을 데이터 웨어하우스로 복사해오는 코드<br>
      - Airflow 프레임워크를 주로 사용(오픈 소스 프로젝트, python 3 기반)
      - AWS와 구글 클라우드에서도 지원<br>
<br>

- 데이터 분석: 중요한 지표(매출액, 월간/주간 액티브 사용자 수 등)를 정의하고 대시보드 형태로 시각화<br>
  - 시각화 대시보드: 중요한 지표를 시간의 흐름과 함께 보여주는 것이 일반적<br>
    지표의 경우 **3A(Accessible-한 눈에 봐도 이해 가능, Actionable-향후 조치사항이 명확, Auditable-검사 방법이 존재)**가 중요
  - 구글 클라우드의 룩커(Looker), 세이즐포스의 태블로(Tableau), 마이크로소프트의 파워 BI(Power BI), 오픈소스 아파치 수퍼셋(Superset)<br>
<br>

- 수집된 데이터, 가공된 데이터를 기반으로 데이터 과학(머신러닝/인공지능)을 적용하여 서비스<br>
<br>

### 데이터 팀의 구성원
- **데이터 엔지니어(Data Enginner)**<br>
  - 데이터 인프라(DW, ETL) 구축, DW는 클라우드로 가는 것이 추세(Redshift, BigQuery, SnowFlake)
  - ETL 코드를 작성하고 주기적으로실행(Airflow 프레임워크를 주로 사용)
  - 기본적으로 SW 엔지니어, 파이썬이 대세로 자바 혹은 스칼라 같은 언어도 아는 것이 좋음
  - 데이터 분석가, 과학자를 지원<br>
<br>

- **데이터 분석가(Data Analyst)**<br>
  - DW의 데이터를 기반으로 지표를 만들고 시각화(대시보드)(Tableau)와 룩커(Looker)등의 툴이 가장 많이 사용, 오픈소스는 Superset)
  - SQL, 통계적 지식, 탄탄한 도메인 지식이 필요
  - 내부 직원들의 데이터 관련 질문 응답, 임원들이나 팀 리더들이 데이터 기반 결정을 내릴 수 있도록 도와줌<br>
<br>

- **데이터 과학자(Data Scientist)**<br>
  - 과거 데이터를 기반으로 미래를 예측하는 머신러닝 모델 제작
  - 문제에 맞춰 가설을 세우고 데이터를 수집한 후 예측 모델을 만들고 이를 테스트 
  - 고객들의 서비스 경험을 개선(개인화 혹은 자동화 혹은 최적화)
  - 머신러닝/인공지능에 대한 깊은 지식과 경험, 코딩 능력(파이썬, SQL), 통계 지식, 수학 지식이 필요<br>
<br>

### 데이터 팀의 구조
- 중앙집중 구조: 모든 데이터 팀원들이 하나의 팀으로 존재
- 일의 우선 순위는 중앙 데이터 팀이 최종 결정
- 데이터 티무언들간의 지식과 경험의 공유가 쉬워지고 커리어 경로가 더 잘 보임
- 현업부서들의 만족도는 상대적으로 떨어짐<br>
<br>

- 분산 구조: 데이터 팀이 현업 부서별로 존재
- 일의 우선 순위는 각 팀별로 결정
- 데이터 일을 하는 사람들간의 지식/경험의 공유가 힘들고 데이터 인프라나 데이터 공유가 힘듦
- 현업부서들의 만족도는 처음에는 좋지만 데이터 팀원들의 만족도는 떨어짐<br>
<br>

- **하이브리드 모델: 중앙집중 구조와 분산 구조를 혼합한 형태**
- 가장 이상적인 구조
- 데이터 팀원들 일부는 중앙에서 인프라적인 일을 수행
- 일부는 현업팀으로 파견, 주기적으로 일을 변경
- 데이터 팀 안에서 커리어 경로가 만들어짐<br>
<br>

### 모델 개발 시 고려할 점
- 개발된 모델의 이양 관련해서 마찰이 많이 생김
- 누군가 **모델 개발부터 최종 론치까지 책임질 사람이 필요**
- 참여하는 사람들이 같이 크레딧을 받아야 협업이 더 쉬워짐<br>
<br>
- 모델 개발 **초기부터 개발/론치 과정을 구체화하고 소통**<br>
  ex) 모델 검증방법, 어떤 형태로 모델을 엔지니어들에게 넘길 것인지?<br>
     (피처 계산, 모델 자체는 어떤 포맷?, A/B테스트 시 최종 성공판단 지표 ...)<br>
<br>
- 개발된 모델이 **바로 프로덕션에 론치가능한 프로세스/프레임워크 필요** (R로 개발된 모델은 프로덕션 론치 불가능)
- 트위터: 데이터 과학자들에게 특정 파이썬 라이브러리로 모델개발 정책화
- **AWS의 SageMaker**(Google Cloud와 Azure에서도 비슷한 프레임워크 지원): 머신러닝 모델개발, 검증, 론치, 프레임워크<br>
<br>
- **첫 모델 론치는 시작일 뿐 운영을 통해 점진적인 개선**을 이뤄내는 것이 중요
- **피드백 루프**가 반드시 필요한데 운영에서 생기는 데이터를 가지고 개선점을 찾아야 함(검색의 경우 CTR을 모니터링하고 모든 데이터 기록)
- 주기적으로 모델을 재빌딩(**온라인 학습**: 모델이 프로덕션에서 사용되면서 계속적으로 업데이트되는 방식의 머신러닝)<br>
<br>

### 데이터를 통해 매출이 발생해야 함
- **회사의 존재 이유: 매출 창조 혹은 경비 절감**
- 데이터 인프라와 데이터 팀원(데이터 과학자)의 몸값은 상대적으로 높음
- 직접적이건 간접적이건 데이터를 통해 회사 수익에 긍정적인 영향을 끼쳐야함<br>
<br>
- 데이터 인프라 없이는 데이터 분석이나 모델링은 불가능
- 데이터 인프라 구축 이외 약간의 분석/모델링 스킬이 있는 사람이 중요
- 고려사항: 클라우드 vs 직접 구성, 배치단위로 DW로 데이터 복사 vs 실시간으로 DW로 데이터 복사<br>
<br>
- **Garbage In Garbage OUT**
- 데이터 과학자는 데이터 클리닝에 가장 많은 시간을 쏟음
- 모델링에 드는 시간을 100이라고 하면 그중 70은 데이터 클린업에 들어감
- 중요 데이터의 경우 품질 유지 노력이 필수<br>
<br>
- 항상 성공 척도(지표)를 처음부터 생각해야 함. 즉, 나름대로 가설을 세우는 것이 통찰력을 키우는데 큰 도움
- 지표 계산에 있어서는 객관성이 중요
- 어떻게 계산할 것이고, 다른 사람들에게 어떻게 설명할 것인지를 고려<br>
<br>

### 가능하면 간단한 솔루션으로 해결
- **모든 문제를 딥러닝으로 해결해야 할 필요가 없음**
- 다중 분기로 간단한 논리로 해결할 수 있는지부터 고민!
- 실제 회사에서 딥러닝으로 문제를 해결하는 경우는 드물고 설명도 힘들고 **개발과 론치 모두 시간이 걸림**
- **반복 기반의 점진적인 개발방식** vs 한 큐에 모델 만들기<br>
  즉, 점진적으로 개발하면서(애자일 방식) 원하는 결과가 나오면 중단. 더 개선할 필요 없음<br>
<br>


### 요약
1. 데이터 팀의 목표: 신뢰할 수 있는 데이터를 바탕으로 부가가치 생성
2. 데이터 직군에는 엔지니어, 분석가, 과학자 세 종류 존재
3. 데이터 팀 조직 구조에는 중앙집중, 분산, 하이브리드의 세 종류 존재
4. 모델 개발은 론치와 운영에 초점을 맞춰야 함
5. 데이터 팀의 존재 여부는 여타 팀과 마찬가지로 수익증대가 목표
6. 단순한 솔루션이 제일 좋은 솔루션

<br>

---

### 느낀점
특별히 어떤 개념보다는 현업에 관해 많이 알 수 있었던 시간이었다. 굉장히 유용하고 굉장히 많은 지식을 얻고 있지만<br>
이번 강의에서 들은 내용은 앞으로 현업을 함에 있어서 절대 잊어서는 안될 것 같다.<br>
내일부터는 SPARK강의도 시작되는데 밀리지 말고 차근차근 해나가야할 것 같다.<br>
논문 세미나 자료 준비도도 늑장부리지말고 서둘러서 시작해야할 것 같다.
