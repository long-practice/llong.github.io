---
title: 프로그래머스 인공지능 데브코스 43일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 9주차(22.2.7.(월) ~ 22.2.12.(토)) 
  선형회귀
  선형분류
  Weekly Mission
tags:
- 컨볼루션(합성곱) 신경망(CNN)
- 컴퓨터 비전
- CNN의 구조
- DMLP
- 완전 연결 신경망
- 커널(필터)
- 보폭
- 패딩(덧대기)
- 가중치 공유
- 특징 맵
- 특징 학습
- 풀링
- 빌딩 블록
- VGGNet

use_math: True
---

# 43일차(신경망 기초 - 컨볼루션 신경망(CNN))

9주차(22.2.7.(월) ~ 22.2.12.(토)): 신경망 기초
* 신경망 기초
* 다층 퍼셉트론
* 딥러닝 기초
* monthly project

### 컨볼루션(합성곱) 신경망(CNN)
- 오늘날 영상 분야에서 다양하게 활용됨<br>
  - 분류(classification): 해당 사진이 어떤 사진인지(개인지 고양이인지)
  - 검색(retrieval): 어떤 사진과 유사한 사진을 검색
  - 검출(detection): 사진 내부에 있는 자동차, 버스, 개, 고양이, 사람 등 객체에 박스로 표시하고 추출
  - 분할(segmentation): 객체를 구분하는 것에 더 나아가 픽셀 단위로 객체를 분할<br>
<br>

#### 컴퓨터 비전이 어려운 점<br>
  - 동일한 객체라도 영상을 찍는 카메라의 이동에 따라 모든 픽셀값이 변화
  - 경계색(보호색)으로 배경과 구분이 어려움
  - 조명에 따른 변화
  - 기형적인 형태의 이미지, 영상
  - 일부가 가려진 영상 존재
  - 같은 종류 간의 변화가 큼

#### CNN의 구조
- 컨볼루션 층(CONV): 선형함수인 컨볼루션과 비선형 함수인 활성함수의 조합
- 풀링 층(POOL): 컨볼루션의 얻어진 특징을 통계적으로 압축
- 전체 구조: CONV-POOL-...-FC

---

### DMLP와 CNN의 비교

#### DMLP
- 완전 연결 구조로 높은 복잡도
- 너무 많은 가중치는 학습을 어렵게 만듦
- 학습이 매우 느리고 과잉적합 우려<br>
<br>

#### CNN
- 컨볼루션 연산을 이용한 부분연결(희소 연결) 구조로 복잡도가 낮음
- 컨볼루션 연산은 좋은 특징을 추출하는데 유용
- 격자 구조를 갖는 데이터에 적합
- 수용장은 인간시각과 유사
- 가변 크기의 입력 처리 가능

![1.png](attachment:1.png)

#### 완전 연결 신경망과 CNN의 차별
- 학습에 의해 결정된 복수의 커널들(혹은 필터)에 대응되는 특징들을 추출하는 층: CONV<br>
  - 각 층의 입출력의 특징형상 유지(특징 맵)
  - 영상의 공간 정보를 유지하면서 공간적으로 인접한 정보의 특징을 효과적으로 인식
  - 각 커널(필터)은 파라미터를 공유함으로써 완전 연결 신경망 대비 학습 파라미터가 매우 적음<br>
<br>
- 추출된 영상의 특징을 요약하고 강화하는 층:POOL<br>
<br>
- 가변 크기의 데이터 다루기<br>
  - 완전연결신경망은 특징 벡터의 크기가 달라지면 연산 불가능
  - CNN의 가변 크기를 다룰 수 있는 강점<br>
    - 컨볼루션층에서 보폭을 조정한다거나, 풀링층에서 커널이나 보폭을 조정하여 특징 맵 크기를 조절
- 커널의 값에 따라 커널이 추출하는 특징이 다름
- 영상에서의 ReLU(활성함수) 연산의 예: 사진에서 검은색 픽셀은 음수, 밝은 부분은 양수 >> 밝은 부분만 추출<br>
<br>


#### 컨볼루션(합성곱) 연산
- 컨볼루션은 해당하는 요소끼리 곱하고 결과를 모두 더하는 선형 연산
- $u$는 커널(혹은 필터), $z$는 입력 , $s$는 출력(특징 맵)
- 영상에서 특징을 추출하기 위한 용도로 사용됨(공간 필터)<br>
<br>
- 1차원 입력: $\displaystyle s(i)=z \circledast u=\sum_{x=-(h-1) / 2}^{(h-1) / 2} z(i+x) u(x)$<br>
- 2차원 입력: $\displaystyle s(j, i)=z \circledast u=\sum_{y=-(h-1) / 2}^{(h-1) / 2} \sum_{x=-(h-1) / 2}^{(h-1) / 2} z(j+y, i+x) u(y, x)$

![2.png](attachment:2.png)
<br>

#### 패딩(덧대기)(padding)
- 이미지 가장자리에서 영상의 크기가 줄어드는 효과 방지(각 층의 **입출력의 특징형상 유지**)
- 위 그림에서 입력이 8X8 이었는데 출력이 6X6이 되었으나 이는 이미지 외각에 값을 0으로 패딩(padding)해서 문제 해결이 가능<br>
<br>

#### 가중치 공유(묶인 가중치)
- 모든 노드가 동일한 커널을 사용
- 즉 사진 한 장에 대해 동일한 커널을 적용시킴
- 모델의 복잡도가 크게 낮아짐<br>
<br>

#### 다중 특징 맵 추출
- 커널의 값에 따라 커널이 추출하는 특징이 달라짐(ex. 수직방향, 수평방향 선 혹은 모서리 추출)
- 따라서 하나의 커널만 사용하면 너무 빈약한 특징이 추출
- 3개 커널을 사용하여 3개 특징 맵을 추출하는 상황
- 수십~수백 개의 커널 사용<br>
<br>

#### 특징 학습
- 커널을 사람이 설계하지 않고, 학습으로 찾음
- 예를들어 2차원 영상이 7x7커널을 64개 사용한다면, 학습 시에는 $(7\times7 + 1) \times 64 = 3200$개의 매개변수를 찾아야 함
- DMLP와 마찬가지로 오류 역전파로 커널을 학습<br>
<br>

#### 컨볼루션 연산에 따른 CNN의 특성
- 이동에 동변(신호가 이동하면 이동 정보가 그대로 특징 맵에 반영): 영상 인식이나 물체 이동, 음성 인식 등 효과적
- 병렬 분산 구조<br>
  - 각 노드는 독립적으로 계산 가능하므로 병렬 구조
  - 노드는 깊은 층을 거치면서 전체에 영향을 미치므로 분산 구조<br>
  
<br>

#### 큰 보폭에 의한 다운 샘플링
- 모든 화소에 커널을 적용한다는 것은 보폭을 1로 설정한 셈
- 일반적으로 보폴이 $k$이면 $k$개 마다 하나씩 샘플링하여 커널 적용
- 2차원 영상의 경우 특징 맵이 $1/k^2$로 작아짐<br>
<br>


#### 풀링 연산
- 최대 풀링, 평균 풀링, 가중치 평균 풀링 등 특징 맵의 사이즈를 다운 샘플링
- 이 때 일정 영역에서의 최대값 혹은 평균값 등 대표되는 값을 추출하여 특징 맵의 크기를 줄여버림<br>
<br>
- 상세 내용에서 요약 혹은 평균 등의 통계적 대표성을 추출하며, 매개변수가 없음
- 특징 맵의 수를 그대로 유지하고, 연산을 효율적으로 바꿈(연산 횟수, 연결 가중치 개수를 줄임)
- 작은 변화에 둔감: 물체 인식이나 영상 검색 등에 효과적임<br>
<br>

#### 빌딩 블록
- CNN은 빌딩 블록을 이어 붙여 기픈 구조로 확장
- 컨볼루션층 > 활성함수(주로 ReLU) > 풀링 층
- 다중 커널을 사용하여 다중 특징 맵을 추출<br>

![3.png](attachment:3.png)

### 예제

- 입력: W1 x H1 x D1
- K개 F x F 커널, 보폭: S, 패딩(덧대기): P
- 출력의 크기: W2 x H2 x D2<br>
<br>

- W2 = (W1 - F + 2P)/S + 1
- H2 = (H1 - F + 2P)/S + 1
- D2 = K<br>
<br>

- 매개변수의 수: 커널마다 (F x F x D1)개의 가중치와 1개의 바이어스, 따라서 전체 매개변수의 수는 (f x F x D1) x K + K

- 일반적으로 F = 2, S = 2 혹은 F= 3, S = 1을 사용

---

- 입력 크기: 32 x 32 x 3
- 10개의 5 x 5 커널 보폭: 1, 덧대기: 2
- 출력 크기: (32 + 2 x 2 - 5)/1 + 1 = 32 이므로 32 x 32 x 10
- 층의 매개변수 개수: 5 x 5 x 3 + 1 = 76 (bias +1) 이므로 10개에 커널에 대해서 76 x 10 = 760개의 매개변수

### 초창기 CNN 사례: LeNet-5
- 특징 추출: CONV-POOL-CONV-POOL-CONV의 다섯 층을 통해 28* 28 명암 영상을 120차원의 특징 벡터로 변환(평균 풀링 사용)
- 분류: 은닉층이 하나인 MLP
- CNN의 첫 번째 성공사례: 필기 숫자 인식기 만들어 수표 인식 자동화 시스템 구현<br>
![4.png](attachment:4.png)

### VGGNet
- 옥스포드 대학의 연구팀 VGG에 의해 개발된 모델로써, 2014년에 개최된 이미지넷 이미지 인식 대회에서 준우승을 한 모델
- VGGNet은 사용하기 쉬운 구조와 좋은 성능 덕분에 그 대회에서 우승을 거둔 조금 더 복잡한 형태의 GoogLeNet보다 더 인기 있었음
- VGGNet 모델부터 시작해서 네트워크의 깊이가 확 깊어짐<br>
<br>

#### VGGNet의 구조
- 깊이의 영향만을 최대한 확인하고자 컨볼루션 필터커널의 사이즈는 가장 작은 3 x 3으로 고정
- 필터커널의 사이즈가 크면 그만큼 이미지의 사이즈가 금방 축소되기 때문에 네트워크의 깊이를 충분히 깊게 만들기 불가능<br>
<br>
- 입력: 224 x 224 x 3 이미지(224 x 224 RGB 이미지)를 입력
- CONV: 3 x 3 x n 사이즈의 커널로 컨볼루션 연산, 보폭은 1, zero padding 1, 아래 그림참고
- POOL: 최대 풀링 적용
- 마지막에는 4096개의 뉴런과 1000개의 뉴런이 fully connected되어 softmax 함수 적용하여 예측 수행

![5.png](attachment:5.png)

### 느낀점
CNN의 개념에 대해 조금 더 심층적으로 알 수 있었다. 어제 내용과 유사한 내용이 많았지만 시각화된 자료를 통해 쉽게 이해할 수 있었다.<br>
어제는 Alexnet을 통한 실습을 진행했고 오늘은 VGGNet에 대한 실습을 진행하였다.<br>
코딩은 비슷한 흐름이었지만 관련된 내용에 대해 조금 더 찾아보고 보완해야겠다.<br>
관련해서 여러가지 상징적인 사건들이 있던 모델들로 실습을 진행하고 있는데 각각의 탄생 의의들을 잘 곱씹어보아야 할 것 같다
