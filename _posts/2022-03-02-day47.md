---
title: 프로그래머스 인공지능 데브코스 47일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 10주차(22.2.14.(월) ~ 22.2.18.(토)) 
  선형회귀
  선형분류
  Weekly Mission
tags:
- 활성함수
- Sigmoid
- tanh
- ReLU
- Leaky ReLU
- Maxout
- ELU
- 배치 정규화
- 공변량 변화 현상
- 규제
- 가중치 벌칙
- 조기 멈춤
- 데이터 확대(증진)
- 드롭아웃
- 앙상블
- 하이퍼 파라미터 최적화
- 뉴턴 방법
- 켤레 경사도
- 유사 뉴턴 방법
- DenseNet

use_math: True
---
# 47일차(신경망 기초 - Deep Learning 기초)

10주차(22.2.14.(월) ~ 22.2.18.(금)): CNN & RNN
* Deep Learning 기초
* CNN Models
* Deep Learning 최적화
* RNN
* weekly mission
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

### 활성함수
- **선형 연산 결과인 활성값에 대해 비선형 활성함수를 적용하는 과정**
- 선형 $\rightarrow$ 계단(1950년대) $\rightarrow$ s자 활성함수(1980년대) $\rightarrow$ ReLU(2000년대 ~ 현재)
- s자 활성함수는 활성값이 커지면 포화 상태가 되고 경사도가 0에 가까운 값을 출력(경사 소멸 문제) $\rightarrow$ 더딘 학습 속도
- ReLU 활성함수는 포화 상태의 활성값에서 발생하는 경사 소멸 문제를 해결
- ReLU 함수의 변형 중 하나인 Leaky ReLU<br>
<br>

#### 여러가지 활성함수
- Sigmoid, tanh, ReLU 외
- Leaky ReLU<br>
  $\text{leakyReLU}(z) = \operatorname{max}(0.1x, x)$<br>
<br>

- Maxout<br>
  $\text{Maxout}(z) = \operatorname{max}(w_1^Tx+b_1, w_2^Tx + b_2)$<br>
<br>

- ELU(exponential linear units)<br>
  $\text{ELU}(z) = \begin{cases}x &  x \geq 0 \\\\\\ \alpha\left(e^{x}-1\right) &  x<0\end{cases}$<br>
<br>
- 최근에는 활성 함수들을 통해 여러가지 문제(경사 소멸문제, 출력값의 중심을 0을 벗어나는 문제, 높은 연산문제 등)를 해결하고자 함

---

### 배치 정규화

#### 공변량 변화 현상
- **훈련 집합과 테스트 집합의 분포가 다르기 때문에 발생**
- 학습이 진행되면서 첫번째 층의 매개변수가 바뀜에 따라 $\widetilde{\mathbb{X}}^{(1)}$가 바뀜
- 즉, 두번째 층 입장에서 보았을 때 입력 데이터의 분포가 수시로 바뀌는 것과 같음
- 따라서 층이 깊어질수록 이 현상(**공변량 시프트 현상**)은 학습을 방해하는 요인으로 작용<br>
<br>

#### 배치 정규화
- 공변량 시프트 현상을 해결하기 위해 정규화를 층 단위로 적용
- 정규화를 적용하는 시점은 **선형연산을 마치고 비선형 연산을 하기 전에 정규화**를 시켜주는 것이 가장 좋음
- 그 이유는 활성함수를 통과하기 전 양극단에 있는 값들을 중앙으로 모아주기 때문에 학습이 더 잘됨
- 훈련 집합 전체 보다는 미니배치 단위로 적용하는 것이 효율적이므로 유리, 그렇다고 배치 사이즈를 너무 줄여버리면 학습이 잘 이루어지지 않을 수 있음<br>
<br>

- 미니배치 단위로 평균과 분산을 구하고 정규화를 진행한 후 비례와 이동을 통한 세부 조정이 이루어짐<br>
  - 비례($\gamma$): 정규화된 그래프의 스케일을 조정(분산을 조정)
  - 이동($\beta$): 정규화된 그래프의 위치를 조정(평균을 조정)<br>
<br>
- CNN에서는 노드 단위가 아닌 특징 맵 단위로 배치 정규화가 이루어짐<br>
  **미니배치에 $m$개의 샘플에 대해 $m$개의 특징 맵 발생(1장의 이미지에 대해 $m$개의 커널이 아님)**, 특징 맵에는 $pq$개의 값이 존재<br>
  총 $pqm$개의 값을 가지고 아래 배치 정규화의 과정을 거침<br>
<br>

#### 배치 정규화 장점
- 신경망의 경사도 흐름 개선
- 안정적인 학습 데이터를 정렬시켰기 때문에 탐색이 잘 이루어지고, 이에 따라 높은 학습률로 설정이 가능
- 배치 정규화에 따라 데이터의 분포를 보정, 따라서 가중치를 초기화 함으로써 데이터 분포 보정 의존성 감소
- 규제와 유사한 행동하기 때문에 드롭아웃의 필요성 감소<br>
<br>

#### 배치 정규화의 과정
1. 미니배치 $\mathbb{X}\_B = \\{\mathbf{x}\_1, \mathbf{x}\_2, \cdots, \mathbf{x}\_m\\}$에 대한 활성값<br>
  $\widetilde{\mathbb{X}}\_B = \\{z_1, z_2, \cdots, z_m\\}$<br>
<br>
2. 미니배치 평균<br>
  $\displaystyle \mu_B = \frac{1}{m}\sum_{i = 1}^m z_i$<br>
<br>

3. 미니배치 분산<br>
  $\displaystyle \sigma_B^2 = \frac{1}{m}\sum_{i = 1}^m (z_i - \mu_B)^2$ <br>
<br>

4. 정규화($\epsilon$은 분모가 0이 되게 하는 것을 방지)<br>
  $\displaystyle \tilde{z}\_i = \frac{z_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$ <br>
<br>

5. 비례와 이동($\gamma, \beta$는 학습을 통해 알아냄)<br>
  $z_i^{\prime} = \gamma\tilde{z}\_i + \beta$<br>
<br>

6. 후처리 작업: 각 노드에서 전체 훈련집합에 대한 평균과 분산을 구하고, 저장<br>
  $\displaystyle \mu = \frac{1}{n} \sum_{i=1}^{n} z_i$<br>
  $\displaystyle \sigma^2 = \frac{1}{n} \sum_{i=1}^n (z_i - \mu)^2$<br>
<br>
  
7. 예측 단계에서는 각 노드에서 활성값 $z$에 대해 값을 변환<br>
  $\displaystyle z^{\prime} = \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}}z + \left( \beta - \frac{\gamma\mu}{\sqrt{\sigma^2 + \epsilon}}\right)$<br>
<br>

---

### 규제

#### 과대적합의 이유
- 대부분 가지고 있는 데이터에 비해 훨씬 큰 용량의 모델 사용
- 훈련 집합을 단순히 암기하는 과대적합을 주의해야 함
- 현대 기계 학습의 전략: 충분히 큰 용량의 모델 설계, **학습 과정에서 여러 규제 기법 적용**<br>
<br>

#### 규제의 정의
- **일반화 오류를 줄이려는 의도를 가지고 학습 알고리즘을 수정하는 방법**<br>
  - 명시적 규제: 가중치 감쇠나 드롭아웃처럼 목적함수나 신경망 구조를 직접 수정
  - 암시적 규제: 학습 조기 중단, 데이터 증대, 잡음 추가, 앙상블처럼 간접적으로 영향<br>
- 학습 모델이 훈련집합의 예측을 너무 잘 수행하지 못하도록 방지
<br>

- 가중치에 대한 선호도 표현
- 학습모델 단순화에 따른 일반화 성능 개선<br>
<br>

- 규제를 사용할 경우 목적함수는 다음과 같음<br>
  $J_{regularized}(\Theta) = J(\Theta) + \lambda R(\Theta)$<br>
<br>

#### 가중치 벌칙
- 규제항은 훈련집합과 무관, 데이터 생성 과정에 내재한 사전 지식에 해당
- 규제항은 매개변수를 작은 값으로 유지, 모델의 용량을 제한
- 주로 L1-norm 혹은 L2-norm 사용 $\rightarrow$ 큰 가중치에 벌칙을 가해 가중치를 작게 유지<br>
<br>
- L1-norm에서 $J_{\text{regularized}}(\Theta; \mathbb{X}, \mathbb{Y}) = J(\Theta; \mathbb{X}, \mathbb{Y}) + \lambda\|\Theta\| \longrightarrow \nabla J_{\text{regularized}}(\Theta; \mathbb{X}, \mathbb{Y}) = \nabla J(\Theta; \mathbb{X}, \mathbb{Y}) + \lambda \boldsymbol{\text{sign}(\Theta)}$
- 따라서 그레디언트 학습은 다음과 같이 이루어짐<br>
  $\boldsymbol{\Theta} = \boldsymbol{\Theta} - \rho\nabla J(\Theta; \mathbb{X}, \mathbb{Y}) - \rho \lambda \boldsymbol{\text{sign}(\Theta)}$
- L1-norm에서 희소성 효과(대부분의 가중치가 0이됨) $\rightarrow$ 선형 회귀에 적용하면 특징 선택 효과<br>
<br>

- L2-norm에서 $J_{\text{regularized}}(\Theta; \mathbb{X}, \mathbb{Y}) = J(\Theta; \mathbb{X}, \mathbb{Y}) + \lambda \left\Vert\Theta\right\Vert_2^2 \longrightarrow \nabla J_{\text{regularized}}(\Theta; \mathbb{X}, \mathbb{Y}) = \nabla J(\Theta; \mathbb{X}, \mathbb{Y}) + 2\lambda \Theta$ <br>
- 따라서 그레디언트 학습은 다음과 같이 이루어짐<br>
  $\boldsymbol{\Theta} =\boldsymbol{\Theta}-\rho \nabla J_{\text {regularized }}(\boldsymbol{\Theta} ; \mathbb{X}, \mathbb{Y}) =\boldsymbol{\Theta}-\rho(\nabla J(\boldsymbol{\Theta} ; \mathbb{X}, \mathbb{Y})+2 \lambda \boldsymbol{\Theta}) =(1-2 \rho \lambda) \boldsymbol{\Theta}-\rho \nabla J(\boldsymbol{\Theta} ; \mathbb{X}, \mathbb{Y})$
- L2-norm에서 가중치 감쇠는 단지 $\Theta$에 $(1-2\rho\lambda)$를 곱해주는 셈<br>
<br>

- 규제의 효과는 손실 함수의 최솟값으로부터 원점에서 형성된 규제항의 원에 최대한 접하는 손실 값을 갖도록 가중치를 학습
- 따라서 최종해를 원점에 가까이 당기는 효과(가중치를 작게 유지) $\rightarrow$ 가중치 감쇠 효과
![4.png](attachment:4.png)

---

### 조기 멈춤
- 일정 epoch 이상 학습을 하게 되면 과대적합현상 발생
- 훈련 데이터를 단순히 암기하기 시작
- 조기 멈춤을 하여 검증집합의 오류가 최저 epoch에서 학습을 종료
- $t + 1$과 $t$에서의 오차의 차이가 일정 수준 $\epsilon$보다 낮을 때 학습을 종료<br>
  `if error[t + 1] - error[t] < epsilon: ...`

---

### 데이터 확대
- 과잉적합 방지하는 가장 확실한 방법: 큰 훈련집합 사용
- 데이터 수집은 비용이 많이 드는 작업<br>
  현재 보유중인 데이터를 인위적으로 변형하여 훈련집합을 확대
- 데이터 이동, 회전, 반전 등을 적용

---

### 드롭아웃
- 완전연결층의 노드 중 **일정 비율을 임의 선택하여 제거** $\rightarrow$ 남은 부분 신경망 학습
- 많은 부분 신경망을 만들고 앙상블을 결합하는 기법
- 의미가 더 두드러지는 노드들만 서로 연결 $\rightarrow$ 부분적인 신경망들이 특징들을 추출 $\rightarrow$ 의미들이 세분화<br>
<br>
- 구현 시 참거짓 배열 $\pi$로 노드 제거 여부를 표시
- $\pi$는 (미니배치) 샘플마다 독립적으로 난수로 설정하여 정함
- 일반적으로 입력층 제거 비율 0.2, 은닉층 제거 비율 0.5<br>
<br>
- 드롭아웃을 시켜서 부분신경망을 학습하여 나온 결과는 완전한 신경망을 통과했을 때의 결과와는 차이가 있음
- 따라서 학습 과정에서 드롭아웃 비율만큼 노드들이 드롭아웃이 되었기 때문에 출력 또한 드롭아웃 비율만큼 보정<br>
<br>
- 메모리적인 측면에서 드롭아웃은 참거짓 배열$\pi$만 추가된 것이기 때문에 추가 계산에 대한 부담은 적은 편
- 실제 부담은 신경망의 크기에서 옴(규모가 큰 신경망에서 드롭아웃을 적용)

---

### 앙상블
- 서로 다른 여러 개의 모델을 결합하여 일반화 오류를 줄이는 기법(백지장도 맞들면 낫다!)
- 현대 기계학습은 앙상블도 규제로 여김<br>
<br>

- 서로 다른 예측기를 학습하는 일<br>
  - 서로 다른 구조의 신경망 여러 개를 학습 또는 같은 구조를 사용하지만 서로 다른 초기값과 하이퍼 매개변수를 설정하고 학습
  - 배깅: 훈련집합을 여러 번 샘플링하여 서로 다른 훈련집합을 구성
  - 부스팅: $i$번째 예측기가 틀린 샘플을 $i + 1$번째 예측기가 잘 인식하도록 연계성 고려 $\rightarrow$ 모델 간 상호보완적인 관계를 형성<br>
<br>

- 학습된 예측기를 결합 $\rightarrow$ 모델 평균<br>
  - 여러 모델의 출력에서 평균을 구하거나 투표하여 최종 결과 결정
  
---

### 하이퍼 파라미터 최적화
- 내부 파라미터 혹은 가중치: 신경망의 경우 가중치 $\Theta$, 학습 알고리즘이 최적화함(주어진 데이터로부터 결정)
- 하이퍼 파라미터: 모델의 외부에서 모델의 동작을 조정(사용자에 의해서 결정) $\rightarrow$ 은닉층의 개수, CNN의 필터 크기, 보폭, 학습률 등<br>
<br>
- 표준 참고 문헌이 제시하는 기본값(여러 후보 값 또는 범위 내)을 사용
- 후보 값 중에서 **주어진 데이터에 최적인 값 선택(하이퍼 파라미터 최적화)**
- 최근 학습을 통한 자동 탐색 방법들이 연구됨(ex. 자동화된 기계학습)<br>
<br>

- 격자 탐색: 하이퍼 파라미터 셋(set)을 맞춰놓고 하이퍼 파라미터를 최적화
- 임의 탐색: 난수를 생성하여 하이퍼 파라미터 조합을 생성, 최적화 **(주로 많이 사용)**<br>
<br>
- 로그 공간 간격으로 탐색: 일정 비율로 하이퍼 파라미터 값들을 증가시키면서 최적화
- 차원의 저주 문제 발생: 매개변수가 $m$개이고 각각이 $q$개 구간이라면 $q^m$개의 점을 조사해야 함<br>
<br>
- 크게 탐색 후 세밀한 탐색: 하이퍼 파라미터가 증가됨에 따른 경향성을 파악을 하고 특정한 의미있는 구간을 세밀한 탐색 <br>
<br>

---

### 하이퍼 파라미터 최적화 - 2차 미분을 이용한 방법
- 현재 널리 활용되지는 않지만 계속 연구되고 있음<br>
<br>

#### 뉴턴 방법
- 1차 미분은 현재 위치에서 지역적인 기울기 정보만 알려줌<br>
  - 경사도를 사용하여 선형 근사를 사용 $\rightarrow$ 근사치 최소화<br>
<br>

- 2차 미분 정보를 활용하여 더 빠르게 해를 찾아가는 경로를 구해냄<br>
  - 경사도와 헤시안을 사용하여 2차 근사 사용 $\rightarrow$ 근사치의 최소값을 알아냄<br>
<br>

- 테일러 급수를 적용<br>
  $\displaystyle J(w+\delta) \approx J(w)+J^{\prime}(w) \delta+\frac{J^{\prime \prime}(w)}{2} \delta^{2}$<br>
  <br>
  다음과 같이 변수가 여러 개일 경우($\mathbf{H}$는 헤시언 행렬)<br>
  $\displaystyle J(\mathbf{w}+\boldsymbol{\delta}) \approx J(\mathbf{w})+\boldsymbol{\nabla} J^{\mathrm{T}} \boldsymbol{\delta}+\frac{1}{2} \boldsymbol{\delta}^{\mathrm{T}} \mathbf{H} \boldsymbol{\delta}$<br>
  <br>
  $\delta$로 미분하고 그 값을 0을 만족시키는 $\delta$값을 찾으면<br>
  $\displaystyle \frac{\partial J(w+\delta)}{\partial \delta} \approx J^{\prime}(w)+\delta J^{\prime \prime}(w) = 0 \Leftrightarrow \delta = -\frac{J^{\prime}(w)}{J^{\prime \prime}(w)}=-J^{\prime \prime}(w))^{-1} J^{\prime}(w)$<br>
  <br>
  변수가 여러 개인 경우, 즉, 벡터와 행렬 연산으로 확장하면 헤시안 $\mathbf{H}$과 1차 도함수로 표현이 가능<br>
  $\boldsymbol{\delta}=-\mathbf{H}^{-1} \boldsymbol{\nabla} J$<br>
  <br>
  
- 기계학습이 사용하는 목적함수는 2차 함수보다 복잡한 함수이므로 한 번에 최적해에 도달 불가능하므로 반복하는 뉴턴 방법을 적용
- 또한 매개변수가 $m$개 일 때 행렬은 $m x m$으로 표현이 가능하며, 이 행렬의 역행렬을 구할 때는 시간복잡도가 O($m^3$)의 시간복잡도가 소요
- 따라서 과도한 연산량을 해결하기 위해 **켤레 경사도 방법**이 대안으로 제시됨<br>
<br>

#### 켤레 경사도
- 직선 탐색: 이동 크기를 결정하기 위해 직선으로 탐색, 미분
- **직전에 사용한 그레디언트 정보와 이번 차례에 구한 그레디언트를 다함께 고려**하여 그레디언트를 업데이트<br>
<br>

#### 유사 뉴턴 방법
- 경사 하강법: 수렴 효율성이 낮음
- 뉴턴 방법: 헤시안 행렬 연산 부담 $\rightarrow$ **헤시안 $\mathbf{H}$의 역행렬을 근사하는 행렬 $\mathbf{M}$을 사용**
- 대표적으로 헤시안을 근사화하는 LFGS가 많이 사용
- $\mathbf{M}$을 저장하는 메모리를 적게 쓰는 L-BFGS를 주로 사용<br>
<br>

---

### DenseNet

#### 구조
- 모든 레이어의 특징 맵을 연결, 즉, 특징 맵들을 서로 완전연결 시킨 형태
- 특징 맵을 연결할 때에는 ResNet에서는 덧셈 연산을 수행 했지만 DenseNet에서는 Concatenate(연결)연산 수행
- 연결을 할 때에는 각 특징 맵의 크기가 동일해야 함
- 층을 통과할 때마다 특징 맵이 증가하기 때문에 각 층의 특징 맵의 채널 수는 작은 값으로 설정<br>
<br>

#### 효과
- 경사 소멸 문제 해결 및 특징 맵 재사용 효과<br>
  - 이전 CNN모델의 경우 층을 깊게 쌓게되면 상대적으로 초반에 학습했던 그레디언트의 영향이 사라지는 경향을 보임
  - DenseNet의 경우 층마다 이전층에서의 특징 맵을 학습데이터로 직접 주기 때문에 신경망 끝에 도달했을 때 특징 맵의 정보들이 사라지지 않음(특징맵 재사용) 
  - 각 층에서 다양한 특징맵들이 생성이 되고 이 특징맵들이 연결돼서 학습되므로 정규화의 효과도 발생<br>
<br>
- DenseNet은 적은 수의 채널을 이용하기 때문에 파라미터 수가 적음<br>
<br>


### 느낀점
딥러닝 최적화에 대해서 알아보았는데 정말 도움이 많이되는 내용들이 많았다. 앞선 과제, 실습에서 무심코 사용했던 코드들의 의미를<br>
다시 살펴볼 수 있었고, 그에 대한 개념도 어느정도 확립시킬 수 있었던 강의였던 것 같다.<br>
많이 중요하다고 여겼기에 반드시 복습도 철저히 해야겠다.<br>
