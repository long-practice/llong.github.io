---
title: 프로그래머스 인공지능 데브코스 56일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 12주차(22.2.28.(월) ~ 22.3.4.(금)) 
  데이터 팀에 관한 커리어 이야기
  빅데이터와 분산처리 시스템
  Hadoop과 Spark에 대한 이해
  Spark를 이용한 데이터 전처리 및 머신러닝 모델 설계
tags:
- 빅데이터
- 대용량 처리 기술
- 분산 컴퓨팅 시스템
- 분산 파일 시스템
- 하둡(Hadoop)
- MapReduce 프로그래밍
- Spark
- HDFS
- Spark의 구조
- YARN
- Spark의 구성
- 세션
- RDD
- DataFrame
- DataSet

use_math: True
---
# 56일차(빅데이터, Hadoop, Spark)

12주차(22.2.28.(월) ~ 22.3.4.(금)): 데이터 팀에 관한 내용, SPARK
* 데이터 팀의 역할
* 커리어 이야기
* SPARK
* SPARK 실습
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

### 빅데이터
- **서버 한 대로 처리할 수 없는 규모의 데이터(분산 처리 불가피)**
- **기존의 소프트웨어로는 처리할 수 없는 규모의 데이터**
- **4V(Volume: 데이터의 크기가 대용량?, Velocity: 처리 속도가 중요?, Variety: 구조화/비구조화 데이터 둘다?, Veracity: 품질이 좋은지?)**<br>
<br>

- 판다스로 처리해야할 데이터가 너무 커서 처리가 불가능할 경우 이용
- 대표적인 기존 소프트웨어: 오라클, MySQL과 같은 관계형 데이터베이스
- 기존 소프트웨어는 분산환경을 염두에 두지 않았고, Scale-up접근 방식으로 메모리, CPU, 디스크를 추가하여 서버의 성능을 높이는 방식
- 빅데이터의 예<br>
  모바일 디바이스(위치정보), 스마트 TV, 각종 센서 데이터(IoT 센서), 네트워킹 디바이스<br>
  웹 페이지: 수십조개 이상의 웹 페이지 존재(크롤링하여 중요한 페이지를 찾아내고 인덱싱하는 것은 엄청난 크기의 데이터 수집, 계산)

### 대용량 처리 기술
- **분산 환경 기반으로 1대 혹은 그 이상의 서버로 구성**
- 분산 컴퓨팅 시스템과 분산 파일 시스템이 필요<br>
  대용량 데이터가 저장되기 위해 **각 서버에 있는 디스크를 하나로 통합하여 대용량의 데이터를 저장(분산 파일 시스템)**
- Fault Tolerance: 소수의 서버가 고장나도 동작해야 함
- 확장이 용이해야 함: Scale Out

### 하둡(Hadoop)
- 빅데이터 시대를 알린 최초의 대용량 분산 처리 기술
- 구글랩 발표 논문들에 기반해 Doug Cutting이 만든 오픈소스 프로젝트
- 처음 시작은 Nutch라는 오픈소스 검색엔진의 하부 프로젝트
- 2006년 아파치 톱레벨 별개 프로젝트로 분리
- 크게 두 개의 서브 시스템으로 구성<br>
  분산 파일 시스템: HDFS<br>
  분산 컴퓨팅 시스템: MapReduce(이전과 다른 특이한 프로그래밍 방식으로 대용량 데이터 처리의 효율을 극대화)
- 하둡은 흔히 이야기하는 Data Warehouse에 해당하며, 워크플로우는 Airflow가 대세<br>
<br>

#### MapReduce 프로그래밍
![1.png](attachment:1.png)
- HDFS에 3개의 조각(partition)이 있을 때<br>
- 3개의 조각에 각각 다른 입력이 들어감
- mapping과정에서 주어진 입력을 단어별로 몇번 등장했는지 key-value쌍으로 나타냄
- 리듀스는 각각의 맵들과 연결되어 각각의 단어가 몇번 등장했는지 종합<br>
  이 때, 같은 키를 가지는 key-value쌍은 같은 리듀스로 넘어감
- 최종적으로 리듀스에서 종합한 결과를 출력으로 반환<br>
<br>
<br>
- 이처럼 MapReduce 프로그래밍은 이전 프로그래밍과 너무 다른 방식
- 기존 프로그래밍 방식보다는 굉장히 성능을 자랑<br>
<br>

- 작업에 따라서 MapReduce 프로그래밍이 너무 복잡
- 나중에는 Hive처럼 MapReduce로 구현된 SQL언어들이 다시 각광을 받게 됨<br>
  SQL on Hadoop으로 빅데이터가 뜨면서 다시 SQL이 각광받음
- MapReduce는 기본적으로 배치 작업에 최적화되어 있어서 실시간 데이터들에 취약한 모습을 보였음<br>
<br>

#### 하둡(Hadoop)의 발전, Spark의 등장
- 하둡 1.0은 HDFS위에 MapReduce라는 분산 컴퓨팅 시스템이 돌아가는 구조로 다른 분산컴퓨팅 시스템을 지원하지 못함
- 하둡 2.0은 아키텍처가 크게 변경되었는데<br>
  우선 기본적으로 하둡은 기반 분산처리 시스템이 되고 그 위에 애플리케이션이 돌아가는 구조<br>
  **Spark지원은 하둡 2.0부터 시작되었고, 애플리케이션 레이어에서 실행**<br>
  즉, HDFS2 위에 **YARN(하둡 2.0에서의 분산 컴퓨팅 시스템)**이 있고, 그 위에 애플리케이션 형태로 MapReduce나 Spark가 돌아가는 구조<br>
<br>
  
#### HDFS - 분산 파일 시스템
- 데이터를 블록단위로 저장(디폴트 128MB)
- 블록 복제 방식으로 각 블록은 3개의 서버에 중복 저장, Fault tolerance를 보장할 수 있음
- 하둡 1.0: 하나의 잡 트래커와 다수의 태스크 트래커(잡 트래커가 일을 나눠서 다수의 태스크 트래커에게 분배)
- 하둡 2.0: 클라이언트, 리소스 매니저, 노드 매니저, 컨테이너로 역할을 세분화

![2.png](attachment:2.png)<br>
<br>
- 이 때, 데이터 저장 및 처리 옵션으로는 Redshift, BigQuery, Snowflake, Hadoop, Spark 등이 있음
- 워크 플로우 관리는 Airflow가 대세

### Spark
- 버클리 대학의 AMPLab에서 아파치 오픈소스 프로젝트로 2013년 시작
- 하둡의 뒤를 잇는 2세대 빅데이터 기술로 하둡 2.0을 분산환경으로 사용 가능하지만 자체 분산환경도 지원
- Scala로 작성었고, Scala, Java, Python 3로 프로그래밍이 가능
- MapReduce보다 쉽게 프로그래밍이 되어있어 사용하기 편함(Pandas 프로그래밍과 굉장히 흡사)
- 머신 러닝 관련해서 많은 개선이 있었음(GPU 지원)<br>
<br>

#### Spark vs MapReduce
- Spark은 기본적으로 메모리 기반, 메모리가 부족해지면 디스크 사용<br>
  MapReduce는 디스크 기반
- Spark은 하둡(YARN) 이외에도 다른 분산 컴퓨팅 환경 지원<br>
  MapReduce는 하둡 위에서만 동작
- Spark은 판다스와 개념적으로 흡사<br>
  MapReduce는 key-value 기반 프로그래밍
- Spark은 다양한 방식의 컴퓨팅(배치 프로그래밍, 스트리밍 프로그래밍, SQL, ML, 그래프 분석 등) 지원<br>
<br>

#### Spark의 구조
- 분산환경 위에 올라가서 분산 컴퓨팅을 담당하는 애플리케이션<br>
  하둡 2.0 혹은 3.0 위에 올라가는 애플리케이션
- 드라이버 프로그램의 존재<br>
  Spark을 드라이브하여 분산 파일 시스템에 있는 데이터들을 조작<br>
<br>

#### Spark의 구성
- Spark Core
- Spark SQL
- SparkStreaming
- MLlib (Spark.ML)
- SparkGraph<br>
<br>

#### Spark 프로그래밍 개념
- RDD(Resilient Distributed Dataset)<br>
  - 로우레벨 프로그래밍 API(map, filter, flatMap 등)로 세밀한 제어가 가능
  - 코딩의 복잡도 증가
- **Dataframe & Dataset(판다스의 데이터프레임과 흡사)**
  - 하이레벨 프로그래밍 API로 점 점 많이 사용되는 추세
  - Spark SQL을 사용한다면 이를 사용
- Scala, Java, Python중 하나 사용

### Spark vs Pandas
- Pandas가 할 수 있는 일<br>
  - 구조화된 데이터 읽고 저장
  - 다양한 통계 추출 및 시각화(matplotlib)
  - 데이터 전처리<br>
<br>

- Pandas의 데이터 구조<br>
  - 데이터 테이블: DataFrame
  - 데이터 테이블 칼럼: Series
  - 입력 DataFrame을 원하는 최종 DataFrame으로 계속 변환하는 것이 핵심<br>
<br>

- Spark 세션<br>
  - 다양한 기능을 사용하기 위해 반드시 세션을 만들어야함
  - 세션을 통해 Spark 클러스터에 명령을 내릴 수 있음
  - Spark 컨텍스트, Hive 컨텍스트, SQL 컨텍스트<br>
<br>

- Spark 데이터 구조<br>
  - RDD<br>
    - 클러스터 내의 서버에 분산된 데이터를 지칭
    - 다수의 파티션으로 구성되고, Spark 클러스터 내 서버들에 나눠 저장
    - 레코드별로 존재하며, 구조화/비구조화 데이터 모두 지원
    - 변경 불가능한 분산 저장된 데이터
    - 외부 데이터가 들어올 경우 반드시 parallelize 함수를 이용하여 RDD로 변환해주어야 함<br>
  - DataFrame<br>
    - RDD위에 만들어지는 하이레벨 데이터
    - RDD와 마찬가지로 변경이 불가능한 분산 저장된 데이터
    - RDD와는 달리 관계형 데이터베이스 테이블처럼 칼럼으로 나눠 저장되고, 필드 정보를 갖고 있음(판다스와 매우 흡사)<br>
    - PySpark에서는 DataFrame을 사용(일반적으로 SparkSQL)
    - SQL 쿼리를 기반으로 DataFrame생성할 수 있고, 외부 데이터를 로딩하여 생성할 수도 있음
  - Dataset<br>
    - DataFrame과는 달리 타입 정보가 존재하며, 컴파일 언어에서 사용 가능<br>

### 느낀점
빅데이터에 관한 내용, 하둡(Hadoop), Spark에 대해 알아보았다. 외울 것이 많아보이지만 이전에 했었던 클라우드, pandas의 개념을<br>
잘 접목해서 생각해본다면 굉장히 유사한 개념들이 많아서 크게 어렵지는 않았다.<br>
많은 기업에서 채용 자격 요건 중하나로 분산 처리 시스템을 경험해보았는지가 항목에 있듯이<br>
절대로 가볍게 여겨서는 안될 것 같은 부분 이라고 생각한다.<br>
<br>

실습을 진행하면서 느낀점은 그래도 pandas와 구조가 굉장히 유사하고, sql과 코드가 유사하게 작성된다는 점이라 쉽게 이해할 수 있었다.<br>
아직 복잡한 문제는 많이 못풀어서 많은 것을 느끼진 못했지만 더 노력하고 공부해야할 것 같다.
