---
title: 프로그래머스 인공지능 데브코스 56일차(보충)
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 12주차(22.2.28.(월) ~ 22.3.4.(금)) 
  데이터 팀에 관한 커리어 이야기
  빅데이터와 분산처리 시스템
  Hadoop과 Spark에 대한 이해
  Spark를 이용한 데이터 전처리 및 머신러닝 모델 설계
tags:
- Spark 실습

use_math: True
---
### Spark 실습

**실습환경: 구글 Colab**

pyspark 패키지: python으로 Spark객체를 만들고 클러스터 내부를 작동시키는 함수들을 포함<br>
Py4j 패키지: 파이썬 프로그램이 자바 가상머신 상의 오브젝트들을 접근할 수 있게 해줌

<br>
<br>

#### Spark 세션 만들기


<br>
<br>



#### python 객체를 RDD로 변환

<br>
<br>


#### 파이썬 리스트를 RDD로 변환
- RDD로 변환되는 순간 Spark 클러스터들의 서버들에 데이터가 나눠 저장(파티션)
- Lazy Execution: RDD가 어떤 의미있는 작업을 수행할 때 데이터가 RDD로 변환
- 만약 천만 개의 데이터를 뽑는다고 생각하면<br>
  위의 방식으로 데이터를 뽑을 경우 굉장히 많은 시간이 걸리지만<br>
  분산 처리 방식으로는 굉장히 빨리 끝낼 수 있음

<br>
<br>

#### 파이썬 리스트를 데이터프레임으로 변환

<br>
<br>

#### califonia housing 데이터를 이용한 데이터 처리 

<br>
<br>

