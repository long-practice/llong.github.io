---
title: 프로그래머스 인공지능 데브코스 60일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 13주차(22.3.7.(월) ~ 22.3.11.(금)) 
  Spark ML Pipeline
  NLP 개요, 언어모델, 단어 임베딩, 텍스트 전처리
tags:
- Spark mllib 모델 튜닝
- ML Pipeline
- 머신러닝 파일 포맷
- PMML

use_math: True
---
# 60일차(Spark ML Pipeline, Tuning, PMML)

13주차(22.3.14.(월) ~ 22.3.8.(금)): 빅데이터 총정리, NLP
* 빅데이터 총정리
* NLP 기초(텍스트 전처리, 언어모델, 문서분류, 단어 임베딩) 강의
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

<br>
<br>

### Spark MLlib 모델 튜닝
- 최적의 하이퍼 파라미터를 구하는 과정
- 모델 선택의 중요한 부분은 테스트 방법(**교차 검증(Cross Validation)과 홀드아웃(Train-Validation Split) 테스트 방법**을 지원)
- 하나씩 테스트를 할 것인지 아니면 다수의 경우를 동시 테스트 할 것인지 결정해야 함<br>
<br>
- 아래 세 가지 입력을 줌으로써 모델을 튜닝<br>
    - **Estimator**: ML 모델 혹은 ML Pipeline
    - **Evaluator**: ML 모델 성능을 나타내는 지표(metrics)<br>
      - evaluate 함수가 제공, 인자로 테스트셋의 결과가 들어있는 DataFrame과 파라미터가 제공
      - ML 알고리즘에 따라 다양한 성능지표가 존재
    - **Parameter**: 훈련 반복 횟수 등의 하이퍼 파라미터(parameter map)<br>
      - ParamGridBuilder를 이용하여 ParamGrid 타입의 변수 생성<br>
    - 최종적으로 가장 좋은 결과 모델을 리턴<br>
<br>




### ML Pipeline 사용절차
- 트레이닝 셋에 수행해야 하는 `feature transform`들을 생성
- 사용하고자 하는 머신러닝 모델 알고리즘(`Estimator`)을 생성
- 순서대로 Python 리스트에 추가하고, `Pipeline` 객체를 생성
- 모델 빌딩 방법은 2가지<br>
  - Pipeline의 fit함수를 호출하면서 트레이닝셋 DataFrame 지정
  - ML Tuning 객체로 지정해서 여러 하이퍼 파라미터를 테스트해보고 가장 좋은 결과를 선택<br>
<br>

#### 코드 예시

```
stringIndexer = StringIndexer(...)
imputer = Imputer(...)
assembler = VectorAssembler(...)
minmax_scaler = MinMaxScaler(...)
algo = LogisticRegression(...)

stages = [stringIndexer, imputer, assembler, minmax_scaler, algo]

pipeline = Pipeline(stages = stages)

lr_model = pipeline.fit(train)
lr_cv_predictions = lr_model.transform(test)
evaluator.evaluate(lr_cv_predictions)
```
<br>
<br>

### ML Tuning 사용 절차
- 테스트하고 싶은 머신러닝 알고리즘 객체 생성(혹은 ML Pipeline)
- `ParamGrid`를 만들어 테스트하고 싶은 하이퍼 파라미터 지정
- `Crossvalidation` 혹은 `TrainValidationSplit` 생성
- `fit` 함수 호출한 후 최선의 모델 선택
- `getEstimatorParamMaps`, `getEvaluator`의 조합으로 어느 하이퍼 파라미터 조합으로 최선의 결과를 냈는지 확인 가능<br>
<br>

#### 코드 예시
```
paramGrid = (ParamGridBuilder()
             .addGrid(algo.maxIter, [1, 5, 10])
             .build())
cv = CrossValidator(
     estimator = pipeline,
     estimatorParamMaps = paramGrid,
     evaluator = evaluator,
     numFolds=5)

cvModel = cv.fit(train)

lr_cv_predictions = cvModel.transform(test)
evaluator.evaluate(lr_cv_predictions)
```

<br>

---

### 범용 머신러닝 모델 파일 포맷
- 모델을 설계하고 만드는 과정과 배포하고 실제로 사용하는 과정 사이에는 수많은 단계가 존재
- 이를 해결하기 위해 모델링하는 framework과 모델을 배포하는 framework를 하나로 통일(**AWS SageMaker**)
- 각 framework에서 만들어내는 머신러닝 모델 파일을 동일한 형태의 파일포맷으로 배포(**PMML**)<br>
<br>

- 다양한 머신러닝 개발 플랫폼: Scikit-Learn, PyTorch, Tensorflow 등 + Spark MLlib
- 이런 환경에서 통용되는 머신러닝 파일포맷 혹은 모듈: **PMML, MLeap**이 대표적
- 머신러닝 모델 서빙환경의 통일이 가능(그러나 공통 파일포맷이 지원해주는 기능이 미약해서 복잡한 모델의 경우 지원불가)<br>
<br>

### PMML(Predictive Model Markup Language)
- Machine Learning 모델을 마크업 언어로 표현해주는 XML 언어
- 간단한 입력 데이터 전처리와 후처리도 지원하지만 제약사항이 많음(복잡한 모델의 경우 지원불가)<br>
<br>

#### 전체적인 절차
1. `ML Pipeline`을 `PMML`파일로 저장<br>
  - `pyspark2pmml`파이썬 모듈 설치
  - `pyspark2pmml.PMMLBuilder`를 이용하여 `ML Pipeline`을 `PMML` 파일로 저장<br>
  <br>
  - 코드 예시(`cvModel`은 `ML Pipeline`, `train_fr`은 트레이닝셋 DataFrame)
    ```
    from pyspark2pmml import PMMLBuilder
    
    pmmlBuilder = PMMLBuilder(spark.sparkContext, train_fr, cvModel)
    pmmlBuilder.buildFile("Titanic.pmml")
    ```
    <br>
<br>

2. `PMML` 파일을 기반으로 모델 예측 API로 론치<br>
  - Openscoring framwork
  - AWS SageMaker
  - Flask + PyPMML<br>
<br>

3. API로 입력값을 전송하고 예측값을 받아오는 클라이언트 코드 작성<br>
  - 모델 로딩 및 예측 코드<br>
    ```
    from pypmml import Model
    model = Model.load('single_iris_dectree.pmml')
    
    model.predict({'sepal_length':5.1, 'sepal_width':3.5, 'petal_length':1.4, 'petal_width':0.2})
    ```
<br>
<br>

### 느낀점
지난주 과제를 하면서 ML pipeline을 어떻게 구성을 해야할까 막막했는데 막상 실습을 하고나서<br>
어떻게 하면 좋을지 알 수 있었다. 굉장히 코드가 간편해져서 놀라웠고, 유용하게 사용할 수 있을 것 같다.<br>
나중에 현업에서 막막할 때 기록한 것들을 보면서 잘 적용할 수 있을 것 같다.<br>
<br>
그러나 현업에서는 위 코드를 이용해서 응용을 해야하기 때문에 결국에는 기본 개념을 잘 알아야 할 것 같고, <br>
반드시 복습을 통해서 공부를 계속해야 할 것 같다.
