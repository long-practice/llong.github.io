---
title: 프로그래머스 인공지능 데브코스 25일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 6주차(22.1.3.(월) ~ 22.1.7.(금)) 
  인공지능과 기계학습 소개
  기계학습과 수학 리뷰
  E2E와 선형대수
  weekly mission을 통한 실습
tags:
- 인공지능
- 알파고
- 신경망
- 머신러닝(기계학습)
- 인공두뇌학
- 결합설
- 심층학습
- 회귀(Regression)
- 분류(Classification)
- 훈련
- 추론
- 특징공간
- 차원의 저주
- 표현문제
- 약인공지능
- 강인공지능
- 초인공지능
- 목적 함수(비용 함수)
- 과소적합
- 과잉적합
- 편향
- 분산
- 상충(trade-off)
- 검증 집합
- 교차 검증
- 부트스트랩
- 규제
- 데이터 확대
- 가중치 감쇠
- 지도학습
- 비지도학습
- 준지도학습
- 오프라인 학습
- 온라인 학습
- 결정론적 학습
- 확률적 학습


use_math: True
---
# 25일차(인공지능 소개와 기계학습)

6주차(22.1.10.(월) ~ 22.1.13.(금)): 인공지능과 기계학습 개요
* 인공지능과 기계학습 소개
* 기계학습과 수학 리뷰
* E2E와 선형 대수
* weekly mission을 통한 실습

### 인공지능(Artificial intelligence)
- 세계를 이끌어갈 SW이지만 SW의 중심에는 AI가 있을 것이라는 의견이 대두되고 있음
- 인공지능은 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램 혹은 기기로 실현한 기술
- 쉽게 말해서 인간처럼 생각하고 행동하는 기기를 만들고자 함
<br><br>
- 2016년 이세돌과 알파고의 대결로 인공지능이 많이 알려지게 되었고, 인간 삶으로 인공지능이 들어왔다고 함
- 즉, 인간 삶에 영향을 미칠 수 있는 영역으로 인공지능이 침투된 것을 알 수 있음
<br><br>
- 인공지능의 구현은 레고처럼 조립이 가능, 깊은 신경망을 통해 주어진 문제의 목표를 달성하고 이를 최적화하는 과정을 거침
- 데이터에 대한 이해를 기반으로 접근해야 보다 좋은 인공지능의 구현이 가능
- 인공지능을 만드는 방법을 배우는 것도 중요하지만 **사용하는 방법**또한 배워야 함
<br><br>

#### 참고영상
- 인공지능이란? <https://www.youtube.com/watch?v=D1Tfbg4fHNs>
- 인공지능의 역할 범위? <https://www.youtube.com/watch?v=hqZhH9Qr4B0>
- 인공지능은 선택이 아닌 필수가 되어버린 시대! <https://www.youtube.com/watch?v=j5rDULcDGJo>

### 일상 속 인공지능
- 음성인식(Siri)
- 추천 시스템(eBay, Netflix)
- 자율주행(Waymo)
- 실시간 객체 인식(Face ID)
- 로봇(HUBO)
- 번역(papago)

### 기계학습
- 학습의 사전적 의미: 경험의 결과로 나타나는 비교적 지속적인 행동의 변화나 그 잠재력의 변화 또는 지식을 습득하는 과정
- 경험을 통해 점진적으로 성능이 향상되는 기계를 만들 수 있는지 살펴봄<br>
<br>
- 초창기 정의: 컴퓨터가 경험을 통해 학습할 수 있도록 프로그래밍을 한다면 세세하게 프로그래밍해야 하는 번거로움에서 벗어날 수 있음
- 현대적 정의: 어떤 컴퓨터 프로그램이 경험을 통해 성능이 개선된다면 프로그램은 학습한다고 말할 수 있음 **(최적의 프로그램(알고리즘)을 찾는 행위)**
- 즉, 사례 데이터를 이용해서 성능 기준을 최적화하도록 프로그래밍하는 작업 혹은 정확하게 예측하기 위해 경험을 이용하는 계산학 방법들을 의미
<br><br>
- **기계학습의 3요소: 경험, 작업, 성능**
- 기존의 프로그래밍 방식은 입력과 사람이 알고있는 규칙을 통해 결과를 도출
- 기계학습 방식은 입력과 원하는 결과를 통해 점진적으로 확실한 규칙을 도출

### 인공지능 관련 주요 연구 및 사건
- 1940 ~ 1960년대 초반: 인공지능의 시작을 알린 촉발시대(**인공두뇌학**)<br>
  - 지식기반 방식이 주류, 사람의 뇌를 모방한 형태의 모델
  - 경험적인 지식 혹은 사실을 인위적으로 컴퓨터에 부여하여 학습
  - 한계: 학습의 대상이 **심한 변화 양상**을 가진 경우 모든 지식 혹은 사실의 나열은 불가능
  - 인공지능의 주도권 전환: 지식 기반 > 기계 학습 > 심층 학습(표현 학습)
  - 데이터 중심 접근방식으로 전환<br>
<br>

- 1980 ~ 1990: 기계학습의 번창 시대(**결합설**)<br>
<br>
- 2000 ~ : **심층학습(딥러닝)**의 혁신으로 인공지능 황금 시대

### 기계학습의 개념
- 기계학습의 목표: 문제를 예측
- 예측은 회귀(regression)문제와 분류(classification)문제로 나뉨
- **회귀는 목표치가 실수, 분류는 부류 혹은 종류의 값**<br>
<br>
- 훈련집합: 모델이 경험을 할 수 있도록 제공되는 데이터(특징과 목표치가 대응)
- 관찰된 데이터들은 어떻게 설명할 것인가?<br>
  - 가설을 수립: 아마 데이터 양상은 직선의 양상일 것이다.(모델을 직선으로 선택 가정)
  - 직선 모델의 수식 $y = wx + b$<br>
<br>
- **실제 세계에서는 선형이 아니며 잡음이 섞이기 때문에 비선형 모델이 필요**<br>
<br>

#### 기계학습의 훈련과 추론
- **주어진 문제인 예측을 가장 정확하게 할 수 있는 최적의 매개변수를 찾는 작업(훈련)**
- 처음에는 임의의 매개변수 값에서 시작하지만 **점차적으로 개선하여 정량적인 최적 성능에 도달(훈련의 결과)**<br>
<br>
- 훈련을 마치면, **추론**을 수행, 새로운 특징에 대응되는 목표치의 예측에 사용
- 기계 학습의 궁극적인 목표는 훈련집합에 없는 새로운 데이터(테스트 데이터)에 대한 오류를 최소화
- 즉, 테스트 집합에 대한 높은 성능을 **일반화** 능력이라 부름<br>
<br>

#### 기계학습의 필수요소
- 학습할 수 있는 데이터가 있어야 함
- 데이터 규칙이 존재
- 수학적으로 설명 불가능(수학적으로 설명이 가능하다면 수학적 모델링으로 해결 가능)

### 특징공간
- 모든 데이터는 정량적으로 표현되며, 특징 공간 상에 존재
- 1차원 특징 공간의 예: x=(온도), y=(음료 판매량)
- 2차원 특징 공간의 예: x=(체온, 두통), y=(감기 여부)
- 다차원 특징 공간의 예<br>Iris: x=(꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비), y=(붓꽃의 여부)<br>Mnist: x=(화소1, 화소2, ... , 화소784), y=(사진)<br>
<br>
- $d$-차원 데이터: $x=(x_1, x_2, \cdots, x_d)^T$
- $d$-차원 데이터를 위한 학습 모델의 예<br>
  - 직선 모델을 사용하는 경우 매개변수의 수는 $d + 1$개<br>
    $ y = w_1x_1 + w_2x_2 + \cdots + w_dx_d + b$
  - 2차 곡선 모델을 사용하면 매개변수 수가 지수적으로 증가, 매개변수의 수는 $d^2 + d + 1$개<br>
    $ y = w_1x_1^2 + w_2x_2^2 + \cdots + w_d{x_d}^2 + w_{d+1}x_1x_2 + \cdots + w_d^2x_{d-1}x_d + w_{d^2 + 1}x_1 + \cdots + w_{d^2 + d}x_d + b $<br>
<br>
- 거리: 차원에 무관하게 수식 적용 가능함(두 점 사이의 거리(유클리드 거리)는 모든 $d$에 성립<br>
<center>$dist(a, b)= \sqrt{\displaystyle\sum_{i = 1}^d{(a_i - b_i)^2}}$</center><br>

### 차원의 저주
- 차원이 높아짐에 따라 발생하는 현실적인 문제들
- $d = 784$인 MNIST 샘플의 화소가 0과 1값을 가진다면 $2^{784}$개의 칸이 거대한 공간에 고작 6만 개의 샘플을 흩뿌린 매우 희소한 분포
- **차원이 높아질수록 유의미한 표현을 찾기 위해 지수적으로 많은 데이터가 필요함**

### 표현 문제
- 주어진 데이터를 선형분리가 불가능(표현 문제)할 때 공간변환을 통해 문제해결 가능
- 표현 학습: 좋은 특징 공간을 자동으로 찾는 작업(예를 들어 직교좌표계를 극좌표계, 원통좌표계로 변환 등)
- 심층 학습: 표현학습의 하나로 다수의 은닉층을 가진 신경망을 이용하여 **최적의 계층적인 특징을 학습**

### 기술 추세
- 기계학습 알고리즘과 응용의 다양화
- 표현 학습 강조
- 심층학습이 기계 학습의 주류
- 심층학습은 현대 인공지능 실현에 핵심 기술

### 사회적 전망
- 인공지능의 단계<br>
  1. 약인공지능: 인간이 지시한 명령의 틀(특정 분야의 일) 안에서만 일하기 때문에 예측과 관리가 용이
  2. 강인공지능: 인간이 할 수 있는 어떠한 지적인 업무도 성공적으로 해낼 수 있는 가상적인 기계의 지능
  3. 초인공지능: 인공지능의 발전이 가속화되어 모든 모든 인류의 지성을 합친 것보다 더 뛰어난 인공지능<br>
<br>
- 현재는 약인공지능의 시기이고, 강인공지능으로 도약하기위한 시도를 하는 중

### 데이터와 기계학습
- 과학기술의 정립과정: 데이터 수집 > 모델 정립(가설) > 예측 > 데이터 수집 > ...<br>
  Tycho Brahe는 천동설을 주장했으나 수집한 데이터를 설명하지 못함<br>
  Johannes Kepler는 지동설 모델을 도입하여 제1, 2, 3법칙을 완성
- 기계학습 또한 복잡한 문제, 과업을 다룸(단순한 수학 공식으로 표현 불가능)<br>
  **데이터를 설명할 수 있는 학습 모델을 찾아내는 과정**
- 기계 학습 문제, 즉 현실에서는 데이터 생성과정을 알 수 없음. 단지 주어진 훈련집합으로 가서 모델을 통해 근사 추정만 가능
- 주어진 과업에 적합한 다양한 데이터를 충분한 양만큼 수집하게되면 과업 성능이 향상됨(주어진 과업에 관련된 데이터 확보는 아주 중요!!)<br>
<br>
- MINST데이터는 총 $2^{784}$개의 서로 다른 샘플이 나올 수 있음에도 불구하고 훈련 데이터 샘플은 60000개를 가지고 있음
- 차원에 저주에 따르면 낮은 성능을 보여야 할 것 같은데 성능이 오차율이 0.23%를 기록할 정도로 낮은 이유는?
- 방대한 공간에서 실제 데이터가 발생하는 곳은 **매우 작은 부분 공간**(데이터 희소 특성)
- 매니폴드(manifold) 가정: 고차원의 데이터는 관련된 낮은 차원의 매니폴드에 가깝게 집중되어 있음

### 목적 함수(비용 함수)
- 선형 회귀를 위한 목적 함수
- 평균제곱오차(MSE)<br>
$ J(\Theta) = \frac{1}{n} \displaystyle\sum_{i = 1}^{n}(f_{\Theta}(x_i)-y_i)^2$
- $f_{\Theta}(x_i)$는 예측함수의 예측 출력, $y_i$는 예측함수가 맞추어야 하는 실제 목표치
- 따라서 $f_{\Theta}(x_i)-y_i$는 **오차** 혹은 **손실**<br>
<br>
- 처음에는 최적 매개변수 값을 알 수 없으므로 임의의 난수로 $\Theta_1 = (w_1,b_1)^T$ 설정
- 이후 $\Theta_2 = (w_2,b_2)^T$, $\Theta_3 = (w_3,b_3)^T$, 최적해 $\hat{\Theta}$
- 과정의 진행은 오차를 줄여나가는 방식으로 진행($J(\Theta_1) > J(\Theta_2) > J(\Theta_3)$)

### 과소적합(underfitting)
- 모델의 용량이 작아 오차가 클 수 밖에 없는 현상
- 다차 함수에 비해 **선형 함수가 오차가 크게 발생**
- 훈련집합과 테스트집합 모두 낮은 성능

### 과잉적합(overfitting)
- 예를 들어 12차 다항식 곡선을 가설에 맞는 곡선으로 채택한다면 훈련집합에 대해 거의 완벽하게 근사화함
- 하지만 새로운 데이터에 대해 큰 문제가 발생, 모델의 용량이 크기 때문에 **학습 과정에서 잡음까지 수용**
- 즉, 훈련집합에 과몰입해서 단순 암기한 꼴과 같음
- 따라서 훈련집합에서는 좋은 성능을 보이지만 테스트 집합에서는 낮은 성능을 보임 **(낮은 일반화 능력)**<br>
<br>
- 3~4차는 훈련집합에 대해 12차보다 낮겠지만 테스트집합에서는 높은 성능을 보임
- 따라서 **적절한 용량의 모델을 선택하는 모델 선택 작업이 필요**

### 편향과 분산
- 가설로 낮은 차수의 곡선을 채택한 경우 반복된 훈련집합에 대해서 그래프의 개형이 비슷하지만 오차가 큼<br>
  **편향이 크지만 비슷한 모델을 얻음(낮은 변동)**<br>
- 가설로 높은 차수의 곡선을 채택한 경우 반복된 훈련집합에 대해서 그래프의 개형이 각기 다르나 작은 오차<br>
  **편향이 작지만 크게 다른 모델을 얻음(낮은 변동)**<br>
- 일반적으로 용량이 작은 모델은 편향이 크고 분산이 작음, 복잡한 모델은 편향이 작고 분산이 큼
- 일반화 오차 성능(편향 + 분산)은 용량에 따라 U형의 곡선을 가짐
- 따라서 **편향과 분산은 상충(trade-off)관계**<br>
<br>
- 기계학습의 목표는 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것이 목표(작은 오차, 비슷한 그래프 개형)
- 모델의 편향과 분산은 상충 관계이기 때문에 편향을 최소로 유지하며, 분산도 최대로 낮추는 전략이 필요

### 검증 집합
- 훈련집합과 테스트집합과 별도로 검증집합을 두어서 일반화 성능을 높임(데이터가 많음)
- 검증 집합을 두지 않으면 모델은 훈련집합에 대해서만 특화되어 있기 때문에 모델 튜닝을 하기위해 검증 집합을 둠

### 교차검증
- 비용 문제로 별도의 검증집합이 없는 상황에 유용한 모델 선택 기법(데이터가 적음)
- 훈련집합을 등분하여 학습과 평가 과정을 여러 번 반복한 후 평균 사용

### 부트스트랩
- 임의의 복원 추출 샘플링을 반복(데이터 분포가 불균형일 때 적용)

### 규제
- 현대 기계 학습의 전략으로 용량이 충분히 큰 모델을 선택한 후 **모델이 정상을 벗어나지 않도록 여러 규제 기법을 적용**
- 규제를 통해서 일반화 성능 향상 가능

#### 데이터 확대
- 데이터를 더 많이 수집하면 일반화 능력이 향상됨
- 그러나 데이터 수집은 많은 비용이 듦(실측자료를 사람이 일일이 표식(labeling)해야 함
- 인위적으로 데이터 확대. 즉, 훈련집합에 있는 샘플을 변형(약간 회전 또는 왜곡(원 데이터의 고유 특성은 변하지 않게 주의))하고 추가
- 많은 데이터는 그래프의 변동량이 줄어드는 효과(고차원 > 저차원)를 불러 일으키므로 더 낮은 용량으로 그래프를 표현 가능

#### 가중치 감쇠
- 가중치를 작게 조절하는 기법
- 가중치 감쇠는 **개선된 목적함수를 이용하여 가중치를 작게 조절**하는 규제 기법<br>
$ J(\Theta) = \frac{1}{n} \displaystyle\sum_{i = 1}^{n}(f_{\Theta}(x_i)-y_i)^2 + \lambda\lVert\Theta\rVert_2^2$<br>
  $\lambda\lVert\Theta\rVert_2^2$가 규제 항으로서 가중치 크기를 작게 유지
- 가중치 감쇠의 목적은 원래 가지고 있는 가중치들의 값을 줄여서 용량이 작은 상태의 효과를 얻을 수 있도록 값을 가중치의 값을 조절

### 기계학습의 유형

#### 지도학습
- 특징 벡터 $\mathbb{X}$와 $\mathbb{Y}$(정답 있음)가 모두 주어진 상황
- 회귀(Regression)와 분류(Classification)문제로 구분

#### 비지도학습
- 특징 벡터 $\mathbb{X}$는 주어지는데 목표치 $\mathbb{Y}$가 주어지지 않는 상황(정답 없음)
- 군집화(Clustering) 과업(고객 성향에 따른 맞춤 홍보 응용(추천 시스템) 등)
- 밀도 추정(Density Estimation), 특징 공간 변환 과업(ex. PCA)

#### 강화학습
- 상대적 목표치가 주어지는데 지도 학습과 다른 형태(== 보상(Reward))
- 바둑을 예로 들면, 수를 두는 행위가 샘플인데, 게임이 끝나면 목표치 하나가 부여됨(이기면 1, 패하면 -1)
- 게임을 구성한 샘플들 각각에 목표치를 나누어 주어야 함

#### 준지도학습
- 일부는 $\mathbb{X}$와 $\mathbb{Y}$를 모두 가지지만, 나머지는 $\mathbb{X}$만 가진 상황
- 최근, 대부분의 데이터가 $\mathbb{X}$수집은 쉽지만 $\mathbb{Y}$는 수작업이 필요하여 **최근 중요성 부각**

---

#### 오프라인 학습과 온라인 학습
- 보통은 오프라인 학습을 다루지만 온라인 학습은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행

#### 결정론적 학습과 확률적 학습
- 결정론적에서는 같은 데이터를 가지고 다시 학습하면 같은 예측 모델이 만들어짐
- 확률적 학습은 학습 과정에서 확률 분포를 사용하므로같은 데이터로 다시 학습하면 다른 예측 모델이 만들어짐

#### 분별 모델과 생성 모델
- 분별 모델은 부류 예측에만 관심. 즉, $P(y|x)$의 추정에 관심
- 생성 모델은 $P(x)$ 또는 $P(x|y)$를 추정, 따라서 새로운 샘플을 생성할 수 있음

### 느낀점
2달차 교육이 시작되었고 머신러닝에 대한 내용을 학습하게 되었는데 확실히 실습보다는 이론에 대한 내용이다보니<br>
학습량이 많아졌는데 학습량이 많은 것에 치우쳐서 모르는 내용을 대충 짚고 넘어가는 것을 경계해야할 듯 싶다.<br>
아직까지는 많이 보고 공부했던 내용들이라 어렵지는 않으나 나중에 심화된 내용을 공부할 때에는 더 집요하게 파고들어야 할 듯 싶다.<br>
