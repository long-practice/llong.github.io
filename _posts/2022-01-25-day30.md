---
title: 프로그래머스 인공지능 데브코스 30일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 7주차(22.1.17.(월) ~ 22.1.21.(금)) 
  확률이론
  결정이론과 선형회귀
  확률분포
  캐글 경진대회
  weekly mission을 통한 실습
tags:
- 기계학습(Machine Learning)
- 연속확률변수
- 누적분포함수
- 확률밀도함수
- 확률이론
- 빈도주의
- 베이지안
- 사후확률
- 사전확률
- 우도(가능도) 함수
- 정규분포
- 가우시안 분포
- 곡선근사

use_math: True
---
# 30일차(ML_basics - Probability)

7주차(22.1.17.(월) ~ 22.1.21.(토)): ML_basic1
* 확률이론
* 결정이론
* 선형회귀
* 확률분포
* kaggle 경진대회
* Weekly Mission

### ML개요 리뷰
- 기계학습(머신러닝): 경험을 통해 자동으로 개선하는 알고리즘의 연구
- 학습데이터: 입력벡터($x_1, \cdots, x_n$), 목표값($t_1, \cdots, t_n$)
- ML알고리즘 결과: 목표치를 예측하는 함수 $y(x)$
- MNIST 데이터의 경우 입력은 이미지, 목표값은 이미지에 맞는 숫자<br>
<br><br>
- 학습단계(training or learning phase): 함수 $y(x)$를 학습데이터에 기반 해결하는 단계
- 시험 셋(test set): 모델을 평가하기 위해 사용하는 새로운 데이터
- 일반화(generalization): 모델에서 학습 시 사용된 데이터가 이전에 잡히지 못한 새로운 데이터에 대해 올바른 예측을 수행하는 역량<br>
<br><br>
- 다항식 곡선 근사에서 입력벡터 $X = (x_1, \cdots, x_n)$, 목표값 $T= (t_1, \cdots, t_n)^T$
- 목표: 새로운 입력벡터 $\hat{x}$가 주어졌을 때 목표값 $\hat{t}$를 예측하는 것
- $y(x, w) = \sum_{j}w_jx^j$ ($w$에 관해서는 선형관계)
- 오차함수: $\displaystyle E(w) = \frac{1}{2} \sum_{n=1}^{N}\{y(x_n, w) - t_n\}^2$
- 오차함수를 최소화하는 방향으로 $w$를 조정하여 $y(x, w)$도출<br>
<br><br>
- 과소적합: 너무 데이터를 근사하지 못한 경우로, 학습 및 테스트 데이터에서 오차가 크게 발생
- 과대적합: 데이터의 잡음까지 즉, 과도하게 근사한 경우로, 학습 데이터에서는 오차가 작으나 테스트 데이터에서 오차가 크게 발생
- 적절한 차원의 모델을 사용해야하며, 데이터가 많아지면 고차원의 복잡한 모델을 사용할 수 있음<br>
<br><br>
- 규제화: 과대적합이 일어날 경우 가중치의 값이 과도하게 커지는 현상이 발생하는데 이 가중치를 낮춰주기 위해 적용
- $\displaystyle \tilde E(w) = \frac{1}{2} \sum_{n=1}^{N}\{y(x_n, w) - t_n\}^2 + \frac{\lambda}{2} \left\Vert w \right\Vert ^2$에서 뒤에있는 $\left\Vert w \right\Vert$가 규제항
- 과도하게 요동치는 그래프를 안정되게 변환시켜줌
- $\lambda$를 크게하면 과대적합을 과도하게 규제하게되고 과소적합 현상 발생

---

### 연속확률변수
- 확률변수: 표본의 집합 $S$의 원소 $e$를 실수값 $X(e) = x$에 대응시키는 함수
- 누적분포함수 $F(x) = P[X \in (-\infty, x)]$
- 누적분포함수 $F(x)$를 가진 확률변수 $X$에 대해서 다음을 만족하는 함수 $f(x)$가 존재
- $X$를 연속확률변수라고 부르고, $f(x)$를 $X$의 확률밀도함수라고 부름
- $\displaystyle F_x(x) = \int_{-\infty}^{x}f_x(t)dt \quad (f_x(t) \ge 0)$이며, $\int_{-\infty}^{\infty}f_x(t)dt = 1 $를 만족<br>
<br><br>
- 확률변수 $X$의 함수 $Y = g(X)$ 그리고 $X = w(Y)$가 역함수 관계에 있을 때(하나의 확률변수 값 x가 하나의 확률변수 값 y에 대응될 때) 다음을 만족
- $P_y(y) = P_x(x) \left\vert \frac{dx}{dy} \right\vert$<br>
<br><br>
- $k$차원의 확률변수 벡터 $X$가 주어졌을 때 $y_i = g_i(x)$롤 정의되어지면 $y = g(x)$로 표현 가능
- 또한 위와 마찬가지로 하나의 확률변수 값 x가 하나의 확률변수 값 y에 대응될 때 $y$의 결합확률밀도함수는 다음을 만족
- $P_y(y_1, \cdots, y_k) = P_x(x_1, \cdots, x_k)\left\vert J \right\vert$<br>
$\displaystyle \left\vert J \right\vert = \begin{vmatrix} \frac{\partial{x_1}}{\partial{y_1}}&\frac{\partial{x_1}}{\partial{y_1}}& \cdots&\frac{\partial{x_1}}{\partial{y_k}} \\
\frac{\partial{x_2}}{\partial{y_1}}& \ddots && \vdots \\
\vdots &&\ddots& \vdots \\
\frac{\partial{x_k}}{\partial{y_1}}& \cdots & \cdots & \frac{\partial{x_k}}{\partial{y_k}} \end{vmatrix}$<br>
<br><br>

#### Inverse CDF Technique
- 확률변수 $X$가 CDF $F_x(x)$일 때 연속확률분포함수 $U \~ UNIF(0, 1)$의 함수로 정의되는 $Y = F_X^{-1}(U)$에서 확률변수 $Y$는 확률변수 $X$와 동일한 분포<br>
<center> $F_Y(y) = P[Y \le y] = P[F_x^{-1}(U) \le y] = P[U \le F_x(y)] = F_x(y)$ </center><br>
- 반지름이 $r$인 원에 무작위로 점을 찍는 프로그램에서
- $F(d) = \frac{\pi d^2}{\pi r^2} = \frac{d^2}{r^2} = U \rightarrow F^{-1}(U) = r\sqrt{U}$

### 빈도주의 vs 베이지안
- 확률을 두가지 관점에서 해석이 가능
- 빈도주의: 반복가능한 사건들의 빈도 수에 기반
- 베이지안: 불확실성을 정량적으로 표현
- 반복가능하지 않는 사건의 예: 북극 얼음이 이번 세기말까지 녹아 없어질 확률
- **이미 알고 있는 정보(얼음이 녹는 속도)에 근거해 확률을정량적으로 나타낼 수 있고 새로운 데이터에 대해 업데이트 가능**<br>
<br>
- 모델의 가중치 $w$에 대한 우리의 지식을 확률적으로 나타낼 때 $w$에 대한 사전 지식은 사전확률(prior)이 됨
- 새로운 데이터$\mathcal{D} = \{t_1, \cdots, t_N\}$를 관찰하고 난 뒤의 조건부확률 $P(\mathcal{D} \mid w)$을 우도함수(likelihood)라고 함
- $P(\mathcal{D} \mid w)$는 $\mathcal{D}$를 관찰하고난 뒤의 $w$에 대한 불확실성 표현
- 사후확률(poesterior) $\propto$ 우도함수 $\times$ 사전확률<br>
<br>
- 빈도주의는 $w$가 고정된 파라미터, 최대우도와 같은 추정자(estimator)를 사용해서 값을 구하며, 불확실성은 부트스트랩 방식으로 구함
- 베이지안 관점의 장점은 사전확률을 모델에 포함시킬 수 있음<br>
<br>
- 동전을 세 번 던져서 모두 앞면이 나왔을 때
- 최대우도: 앞 면이 나올 확률은 1(관측값 모두 앞면이므로)
- 베이지안: 극단적인 확률을 피할 수 있음, 즉, 사전에 얻은 정보에 의거 확률이 $\frac{1}{8}$임을 알 수 있음

---

### 정규분포
- 단일변수 $x$를 위한 가우시안 분포는 아래와 같음
- 평균 $\mu$와 분산$\sigma ^2$으로 정의<br>
$ \displaystyle \mathcal{N}(x | \mu, \sigma ^2) = \frac{1}{\sigma \sqrt{2 \pi}} exp\left(- \frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)$<br>
<br>
- 가우시안 분포가 정규화 됨을 보임<br>
$ \displaystyle \int_{-\infty}^{\infty} \mathcal{N}(x|\mu, \sigma ^2)dx = 1$<br>
<br>

#### 증명 1
정규분포 정규화(Normalization)<br>
$\displaystyle I = \int_{-\infty}^{\infty}exp\left(- \frac{1}{2}\left(\frac{x}{\sigma}\right)^2\right)dx = \sqrt{2\pi\sigma^2}$을 증명<br>
<br>
$I^2$에서 이중적분으로 접근, 극좌표계로 변환하여 해결가능<br>
<br>

#### 증명 2
정규분포 기댓값(Expectation)<br>
$\displaystyle \mathbb{E[x]} = \int_{-\infty}^{\infty}\mathcal{N}(x | \mu, \sigma ^2)xdx = \int_{-\infty}^{\infty}\frac{1}{\sigma \sqrt{2 \pi}} exp\left(- \frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)xdx = \mu$을 증명<br>
<br>
$ y = x - \mu $로 치환하여 해결가능<br>
<br>

#### 증명 3
정규분포 분산(Variance)<br>
$ var[x] = y = \sigma ^2 $을 증명<br>
<br>
$\displaystyle \int_{-\infty}^{\infty} \mathcal{N}(x|\mu, \sigma ^2)dx = 1 \rightarrow \frac{d}{dy}\int_{-\infty}^{\infty} \mathcal{N}(x|\mu, y)dx = 0$로 해결가능<br>
<br>

#### 증명 4
정규분포 최대우도해(Maximum Likelihood solution)의 평균<br>
$X = (x_1, \cdots, x_N)^T$가 돌깁적으로 같은 가우시안 분포로부터 추출된 N개의 샘플들일 때<br>
$p(X|\mu, \sigma ^2) = p(x_1, \cdots, x_N | \mu, \sigma ^2) = \displaystyle\prod_{n = 1}^{N} \mathcal{N}(x|\mu, \sigma ^2) \quad \rightarrow \quad \ln\{p(X|\mu, \sigma ^2)\} = - \frac{1}{2\sigma^2}\displaystyle\sum_{n=1}^{N}(x_n - \mu)^2 - \frac{N}{2}\ln\sigma^2 - \frac{N}{2}\ln(2\pi)$ 에서<br>
$\mu_{ML} = \frac{1}{N}\displaystyle\sum_{n=1}^{N}x_n$을 증명<br>
<br>
$\displaystyle\frac{\partial}{\partial \mu}\ln p(X|\mu, \sigma^2) = 0$ 를 만족시키는 $\mu$값을 구하게되면 최대우도를 갖게하는 $\mu$의 값을 구할 수 있음<br>
<br>

#### 증명 5
정규분포 최대우도해(Maximum Likelihood solution)의 분산<br>
$\displaystyle y_{ML} = \sigma_{ML} ^2 = \frac{1}{N} \displaystyle\sum_{n=1}^{N}(x_n - \mu_{ML})^2$을 증명<br>
<br>
$y = \sigma ^2$로 $\sigma$를 치환<br>
$\displaystyle\frac{\partial}{\partial y}\ln p(x|\mu, y) = 0$를 만족시키는 $y$값을 구하게되면 최대우도를 갖게하는 $\sigma^2$의 값을 구할 수 있음
<br><br><br>

---

### 곡선근사: 확률적 관점
- 학습데이터: $X = (x_1, \cdots, x_N)^T, t = (t_1, \cdots, t_N)^T$<br>
<br>
<br>

#### 최대우도 구하기
- 목표값 $t$의 불확실성을 다음과 같이 확률분포로 나타냄<br>
  $p(t|x, w, \beta) = \mathcal{N}(t|y(x,w), \beta^{-1})$<br>
  이 때, 파라미터는 $w, \beta$<br>
<br>
- 파라미터들의 최대우도해를 구해보면<br>
  $\displaystyle \ln p(t|X, w, \beta) = \frac{\beta}{2}\sum_{n=1}^{N}\{y(x_n,w) - t_n\}^2 - \frac{N}{2}\ln{\beta} - \frac{N}{2}\ln(2\pi)$<br>
<br>
- $w$에 관해서 우도함수를 최대화시키는 것은 제곱합 오차함수($\displaystyle \frac{1}{2} \sum_{n=1}^{N}\{y(x_n,w) - t_n\}^2$)를 최소화시키는 것과 동일<br>
<br>
<br>

#### 사전확률 포함
- 사전확률을 포함해서 표현하면<br>
  $p(w|\alpha) = \mathcal{N}(w|0, \alpha^{-1}I) = (\frac{\alpha}{2\pi})^{(M + 1)/2} \exp \{ -\frac{\alpha}{2}w^Tw \} $<br>
<br>
- $w$의 사후확률은 우도함수와 사전확률의 곱에 비례<br>
  $p(w|X, t, \alpha, \beta) \propto p(t|X, w, \beta)p(w|\alpha)$<br>
<br>
- 사후확률을 최대화시키는 것은 아래 함수를 최소화시키는 것과 동일<br>
  $\displaystyle\frac{\beta}{2} \displaystyle\sum_{n=1}^{N}\{y(x_n, w) - t_n\}^2 + \frac{\alpha}{2}w^Tw$<br>
<br>
- 규제화된 제곱합 오차함수를 최소화시키는 것과 동일($\lambda = \alpha/ \beta$)<br>
<br>
<br>

#### 완전한 베이지안 곡선근사
- 완전한 베이지안 방법은 $w$의 분포로부터 확률의 기본법칙만을 사용해서 $t$의 예측분포를 유도<br>
  $p(t|x, X, t) = \int p(t|x, w)p(w|X, t)dw$
  
---

### 느낀점
오늘도 이전에 배웠던 내용들이 많았지만 이전보다 심화하여 배운 내용들이 간혹 있었다.<br>
난잡한 기호들도 등장하여 당황하긴 했지만 천천히 알고 있는 내용을 차근차근 이어나가니 충분히 해낼 수 있었다.<br>
다시 한 번 더 기초를 탄탄히 다지는 것에 대한 중요성을 느낄 수 있었다.
