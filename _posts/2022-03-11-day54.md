---
title: 프로그래머스 인공지능 데브코스 54일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 11주차(22.2.21.(월) ~ 22.2.25.(금)) 
  SQL 소개 및 문법
  SQL을 이용한 데이터분석 실습
  데이터 웨어하우스 Redshift
tags:
- 트랜잭션
- BEGIN / COMMIT, END
- ROLLBACK
- autocommit
- DELETE vs TRUNCATE
- UNION, EXCEPT, INTERSECT
- LISTAGG
- WINDOW
- LAG
- JSON_EXTRACT_ATH_TEXT

use_math: True
---

# 54일차(SQL과 데이터분석 - 기타 고급 문법)

11주차(22.2.21.(월) ~ 22.2.25.(금)): SQL과 데이터분석
* Redshift를 통한 SQL(DDL, DML) 실습
* 고급 문법 소개, 실습
* monthly project
* Docker 세팅
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

### 트랜잭션
- Atomic하게 실행되어야 하는 SQL들을 묶어서 하나의 작업처럼 처리하는 방법
- DDL, DML 중 레코드를 수정/추가/삭제, SELECT는 제외
- BEGIN, END 혹은 BEGIN, COMMIT 사이에 해당하는 SQL들을 사용
- ROLLBACK으로 잘못 COMMIT한 내용들을 되돌릴 수 있음(BEGIN 이전으로 돌아감)<br>
<br>

- Atomic의 의미를 은행 계좌 이체를 예로 설명하면
- 계좌 이체: 인출과 입금의 두 과정
- 인출은 성공, 입금은 실패하면 계좌 이체가 되지 않음
- 따라서 두 과정은 동시에 성공하든지 실패해야함(Atomic)<br>
  반면 계좌 조회만 하는 것은 Atomic에 해당하지 않음
- 이 과정들을 트랜잭션으로 묶어줘야 함<br>
<br>

#### autocommit
`autocommit = True`
- 모든 레코드 수정/삭제/추가 작업이 기본적으로 바로 데이터베이스에 쓰여짐(commit)
- 만일 특정 작업을 트랜잭션으로 묶고 싶다면 BEGIN과 COMMIT/ROLLBACK으로 처리<br>
<br>

`autocommit = False`
- 모든 레코드 수정/삭제/추가 작업이 COMMIT 호출될 때까지 반영되지 않음<br>
<br>

#### 트랜잭션 방식
- Google Colab의 트랜잭션<br>
  - 기본적으로 모든 SQL statement가 바로 커밋
  - 이를 바꿀 때에는 `BEGIN;`, `END;` 혹은 `BEGIN;`, `COMMIT;`을 사용(혹은 `ROLLBACK;`)<br>
<br>

- psycopg2의 트랜잭션<br>
  - autocommit이라는 파라미터로 조절
  - `autocommit = True`는 기본적으로 PostgreSQL의 커밋과 동일
  - `autocommit = False`는 커넥션 객체의 `.commit()`과 `.rollback()`함수로 조절 가능<br>
<br>

#### DELETE vs TRUNCATE
- `DELETE FROM table_name`<br>
  - 테이블에서 모든 레코드를 삭제(`DROP`은 테이블 자체를 삭제)
  - `WHERE`을 사용해 삭제 레코드에 대해 조건을 부여 가능
  - 속도가 느림<br>
<br>

- `TRUNCATE table_name`<br>
  - 마찬가지로 모든 레코드를 삭제
  - 전체 테이블 내용을 빠르게 삭제 시 유리
  - 트랜잭션을 지원하지 않기 때문에 한 번 레코드들을 삭제하면 되돌릴 수 없음

### 기타 유용한 문법
- `UNION`, `EXCEPT`, `INTERSECT`: 합집합, 차집합(`MINUS`로도 가능), 교집합
- `LISTAGG(channel, '->')`: 그룹핑된 레코드들에서 해당 `channel`의 데이터를 쭉 나열, 데이터들은 `->`로 분리
- `WINDOW`<br>
  - `function(expression) OVER ([PARTITION BY expression][ORDER BY expression])
  - 유용한 함수: `ROW_NUMBER`, `FIRST_VALUE`, `LAST_VALUE`, `LAG`
  - 연산 함수: `AVG`, `SUM`, `COUNT`, `MAX`, `MIN`, `MEDIAN`, `Nth_VALUE`<br>
<br>
  - `LAG`<br>
    - 이전 레코드들의 특정 칼럼 값을 참조할 때 사용(예를 들면 1행 전 세션의 채널: `LAG(channel, 1) OVER ... AS prev_channel`)<br>
<br>
- JSON Parsing Functions: `JSON_EXTRACT_ATH_TEXT`<br>
  - JSON의 nested 구조를 지원하지만 JSON의 포맷을 아는 상황이어야 함



### Redshift connection 및 autocommit 제어


```python
import psycopg2

def get_Redshift_connection(autocommit):
    host = # address
    redshift_user = # ID
    redshift_pass = # PW
    port = 5439
    dbname = "dev"
    conn = psycopg2.connect("dbname={dbname} user={user} host={host} password={password} port={port}".format(
        dbname=dbname,
        user=redshift_user,
        password=redshift_pass,
        host=host,
        port=port
    ))
    conn.set_session(autocommit=autocommit)
    return conn
```


```python
# autocommit 제어
conn = get_Redshift_connection(False)
cur = conn.cursor()
```


```python
# (참고) SELECT는 트랜잭션과 아무관련 없음
# python에서 sql사용
cur.execute("SELECT * FROM raw_data.session_timestamp;")
res = cur.fetchall()
for r in res[:10]:
    print(r)
```

    ('00029153d12ae1c9abe59c17ff2e0895', datetime.datetime(2019, 10, 18, 14, 14, 5, 100000))
    ('0004289ee1c7b8b08c77e19878106ae3', datetime.datetime(2019, 11, 16, 21, 20, 14, 447000))
    ('0006246bee639c7a7b11a08e34dd3cc6', datetime.datetime(2019, 8, 10, 16, 33, 14, 980000))
    ('0006dd05ea1e999ddaa041a7091b7b36', datetime.datetime(2019, 7, 6, 19, 54, 15, 83000))
    ('000958fdaefe0dd06f5d7c4e4a5f28d1', datetime.datetime(2019, 11, 2, 14, 52, 30, 183000))
    ('000a3f777828d2cdbee98887561aa130', datetime.datetime(2019, 11, 29, 16, 33, 55))
    ('000a91f3e374e6147d58ed1814247508', datetime.datetime(2019, 7, 17, 14, 24, 16, 880000))
    ('000cb7efa8a05429dd5309b4bea2eb0c', datetime.datetime(2019, 7, 23, 13, 39, 28))
    ('000d0c74074191add6f22e0004db8f76', datetime.datetime(2019, 8, 21, 14, 48, 36))
    ('000d54aadcedee0739d39127955f2cdb', datetime.datetime(2019, 9, 21, 21, 16, 29))


### 실습-사용자별로 처음 채널과 마지막 채널 알아내기

#### CTE를 빌딩블록으로 사용하는 방법


```sql
%%sql

WITH first AS (
    SELECT userid, ts, channel, ROW_NUMBER() OVER(PARTITION BY userid ORDER BY ts) seq
    FROM raw_data.user_session_channel usc
    JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
), last AS (
    SELECT userid, ts, channel, ROW_NUMBER() OVER(PARTITION BY userid ORDER BY ts DESC) seq
    FROM raw_data.user_session_channel usc
    JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
)

SELECT first.userid AS userid, first.channel AS first_channel, last.channel AS last_channel
FROM first
JOIN last ON first.userid = last.userid and last.seq = 1
WHERE first.seq = 1
LIMIT 5;
```

     * postgresql://...
    5 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>first_channel</th>
        <th>last_channel</th>
    </tr>
    <tr>
        <td>27</td>
        <td>Youtube</td>
        <td>Instagram</td>
    </tr>
    <tr>
        <td>29</td>
        <td>Naver</td>
        <td>Naver</td>
    </tr>
    <tr>
        <td>33</td>
        <td>Google</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>40</td>
        <td>Youtube</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>44</td>
        <td>Naver</td>
        <td>Instagram</td>
    </tr>
</table>



#### JOIN 방식


```sql
%%sql

SELECT first.userid AS userid, first.channel AS first_channel, last.channel AS last_channel
FROM (
    SELECT userid, ts, channel, ROW_NUMBER() OVER(PARTITION BY userid ORDER BY ts) seq
    FROM raw_data.user_session_channel usc
    JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
) first
JOIN (
    SELECT userid, ts, channel, ROW_NUMBER() OVER(PARTITION BY userid ORDER BY ts DESC) seq
    FROM raw_data.user_session_channel usc
    JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
) last ON first.userid = last.userid and last.seq = 1
WHERE first.seq = 1
LIMIT 5;
```

     * postgresql://...
    5 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>first_channel</th>
        <th>last_channel</th>
    </tr>
    <tr>
        <td>27</td>
        <td>Youtube</td>
        <td>Instagram</td>
    </tr>
    <tr>
        <td>29</td>
        <td>Naver</td>
        <td>Naver</td>
    </tr>
    <tr>
        <td>33</td>
        <td>Google</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>40</td>
        <td>Youtube</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>44</td>
        <td>Naver</td>
        <td>Instagram</td>
    </tr>
</table>



#### GROUP BY 방식


```sql
%%sql

SELECT 
    userid,
    MAX(CASE WHEN rn1 = 1 THEN channel END) first_touch,
    MAX(CASE WHEN rn2 = 1 THEN channel END) last_touch
FROM(
    SELECT
        userid, channel,
        (ROW_NUMBER() OVER (PARTITION BY usc.userid ORDER BY st.ts)) AS rn1,
        (ROW_NUMBER() OVER (PARTITION BY usc.userid ORDER BY st.ts DESC)) AS rn2
    FROM raw_data.user_session_channel usc
    JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
)
GROUP BY userid
LIMIT 5;
```

     * postgresql://...
    5 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>first_touch</th>
        <th>last_touch</th>
    </tr>
    <tr>
        <td>34</td>
        <td>Youtube</td>
        <td>Naver</td>
    </tr>
    <tr>
        <td>36</td>
        <td>Naver</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>41</td>
        <td>Facebook</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>45</td>
        <td>Youtube</td>
        <td>Instagram</td>
    </tr>
    <tr>
        <td>64</td>
        <td>Youtube</td>
        <td>Youtube</td>
    </tr>
</table>



#### FIRST_VALUE/LAST_VALUE


```sql
%%sql

SELECT DISTINCT
    A.userid,
    FIRST_VALUE(A.channel) OVER(PARTITION BY A.userid ORDER BY B.ts
                               rows between unbounded preceding and unbounded following) AS First_Channel,
    LAST_VALUE(A.channel) OVER(PARTITION BY A.userid ORDER BY B.ts
                               rows between unbounded preceding and unbounded following) AS Last_Channel
FROM raw_data.user_session_channel A
LEFT JOIN raw_data.session_timestamp B ON A.sessionid = B.sessionid
LIMIT 5;
```

     * postgresql://...
    5 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>first_channel</th>
        <th>last_channel</th>
    </tr>
    <tr>
        <td>27</td>
        <td>Youtube</td>
        <td>Instagram</td>
    </tr>
    <tr>
        <td>29</td>
        <td>Naver</td>
        <td>Naver</td>
    </tr>
    <tr>
        <td>33</td>
        <td>Google</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>40</td>
        <td>Youtube</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>44</td>
        <td>Naver</td>
        <td>Instagram</td>
    </tr>
</table>



### 실습-Gross Revenue가 가장 큰 UserID 3개 찾기

#### GROUP BY


```sql
%%sql

SELECT
    userid, SUM(amount) AS Revenue -- userid 하나 당 Revenue 생성
FROM raw_data.session_transaction st
LEFT JOIN raw_data.user_session_channel usc ON st.sessionid = usc.sessionid
GROUP BY userid
ORDER BY Revenue DESC
LIMIT 3;
```

     * postgresql://...
    3 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>revenue</th>
    </tr>
    <tr>
        <td>989</td>
        <td>743</td>
    </tr>
    <tr>
        <td>772</td>
        <td>556</td>
    </tr>
    <tr>
        <td>1615</td>
        <td>506</td>
    </tr>
</table>



#### SUM OVER


```sql
%%sql

SELECT DISTINCT
    userid, SUM(amount) OVER(PARTITION BY usc.userid) AS Revenue -- userid 마다 Revenue가 생성
FROM raw_data.session_transaction st
JOIN raw_data.user_session_channel usc ON st.sessionid = usc.sessionid
ORDER BY Revenue DESC
LIMIT 3;
```

     * postgresql://...
    3 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>revenue</th>
    </tr>
    <tr>
        <td>989</td>
        <td>743</td>
    </tr>
    <tr>
        <td>772</td>
        <td>556</td>
    </tr>
    <tr>
        <td>1615</td>
        <td>506</td>
    </tr>
</table>



### 실습-raw_data.nps 테이블을 바탕으로 월별 NPS 계산
- 0(의향 없음) ~ 10(의향 아주 높음)<br>
  - detractor: 0 ~ 6
  - passive: 7 ~ 8
  - promoter: 9 ~ 10<br>
<br>

- 10, 9점 추천하는 고객 비율에서 0 ~ 6점을 주는 불평 고객 비율을 뺀 것<br>
  NPS = promoter - detractor<br>
  
<br>

- 현재 raw_data.nps에 created 칼럼이 없는 상황


```sql
%%sql

SELECT month,
    ROUND((promoters-detractors)::float/total_count*100, 2) AS overall_nps
FROM (
    SELECT LEFT(created, 7) AS month,
        COUNT(CASE WHEN score >= 9 THEN 1 END) AS promoters,
        COUNT(CASE WHEN score <= 6 THEN 1 END) AS detractors,
        COUNT(CASE WHEN score > 6 AND score < 9 THEN 1 END) AS passives,
        COUNT(1) AS total_count
    FROM raw_data.nps
    GROUP BY month
    ORDER BY month
);
```


```sql
%%sql

SELECT LEFT(created, 7) AS month,
    ROUND(SUM(CASE
        WHEN score >= 9 THEN 1
        WHEN score <= 6 THEN -1 END):: float*100/COUNT(1), 2)
FROM raw_data.nps
GROUP BY month
ORDER BY month;
```

### 여러가지 문법 - LISTAGG


```sql
%%sql

SELECT userid, LISTAGG(channel)
FROM raw_data.user_session_channel
GROUP BY userid
HAVING userid = 1985;
```

     * postgresql://...
    1 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>listagg</th>
    </tr>
    <tr>
        <td>1985</td>
        <td>GoogleFacebookFacebookFacebookGoogleFacebookGoogleNaverOrganicOrganicOrganicInstagram</td>
    </tr>
</table>




```sql
%%sql

SELECT userid, LISTAGG(channel,'-->')
FROM raw_data.user_session_channel
GROUP BY userid
HAVING userid = 1985;
```

     * postgresql://...
    1 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>listagg</th>
    </tr>
    <tr>
        <td>1985</td>
        <td>Google--&gt;Facebook--&gt;Facebook--&gt;Facebook--&gt;Google--&gt;Facebook--&gt;Google--&gt;Naver--&gt;Organic--&gt;Organic--&gt;Organic--&gt;Instagram</td>
    </tr>
</table>



### 여러가지 문법 - LAG


```sql
%%sql

SELECT usc.*, st.ts, LAG(channel, 1) OVER (PARTITION BY userid ORDER BY ts) prev_channel
FROM raw_data.user_session_channel usc
JOIN raw_data.session_timestamp st ON usc.sessionid = st.sessionid
ORDER BY usc.userid, st.ts
LIMIT 10;
```

     * postgresql://...
    10 rows affected.





<table>
    <tr>
        <th>userid</th>
        <th>sessionid</th>
        <th>channel</th>
        <th>ts</th>
        <th>prev_channel</th>
    </tr>
    <tr>
        <td>27</td>
        <td>a67c8c9a961b4182688768dd9ba015fe</td>
        <td>Youtube</td>
        <td>2019-05-01 17:03:59.957000</td>
        <td>None</td>
    </tr>
    <tr>
        <td>27</td>
        <td>b04c387c8384ca083a71b8da516f65f6</td>
        <td>Google</td>
        <td>2019-05-02 19:21:30.280000</td>
        <td>Youtube</td>
    </tr>
    <tr>
        <td>27</td>
        <td>abebb7c39f4b5e46bbcfab2b565ef32b</td>
        <td>Naver</td>
        <td>2019-05-03 20:38:40.730000</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>27</td>
        <td>ab49ef78e2877bfd2c2bfa738e459bf0</td>
        <td>Facebook</td>
        <td>2019-05-04 21:48:07.300000</td>
        <td>Naver</td>
    </tr>
    <tr>
        <td>27</td>
        <td>f740c8d9c193f16d8a07d3a8a751d13f</td>
        <td>Facebook</td>
        <td>2019-05-05 18:15:30.540000</td>
        <td>Facebook</td>
    </tr>
    <tr>
        <td>27</td>
        <td>ef452c63f81d0105dd4486f775adec81</td>
        <td>Google</td>
        <td>2019-05-06 17:49:15.437000</td>
        <td>Facebook</td>
    </tr>
    <tr>
        <td>27</td>
        <td>d7f426ccbc6db7e235c57958c21c5dfa</td>
        <td>Google</td>
        <td>2019-05-07 20:41:25.293000</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>27</td>
        <td>df334b223e699294764c2bb7ae40d8db</td>
        <td>Facebook</td>
        <td>2019-05-08 17:35:16.440000</td>
        <td>Google</td>
    </tr>
    <tr>
        <td>27</td>
        <td>02c27682b80b462437ba4efc71267562</td>
        <td>Organic</td>
        <td>2019-05-09 19:57:40.037000</td>
        <td>Facebook</td>
    </tr>
    <tr>
        <td>27</td>
        <td>ca9541826e97c4530b07dda2eba0e013</td>
        <td>Organic</td>
        <td>2019-05-10 17:57:10.207000</td>
        <td>Organic</td>
    </tr>
</table>



### 느낀점
SQL 강의가 끝이 났다. 처음에는 대부분 아는 내용이어서 수월하겠거니 했는데,<br>
매일 내주시는 과제를 하면서 굉장히 난감한 부분이 많았고, 또 모르는 문법, 까먹은 문법들이 많아서<br>
이번 기회를 통해 개념을 확립하게 되었다. 강의 자체도 굉장히 세부적으로 잘 알려주셔서 이해하는데 어렵지 않아서 좋았다.
