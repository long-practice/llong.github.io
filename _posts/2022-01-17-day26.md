---
title: 프로그래머스 인공지능 데브코스 26일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 6주차(22.1.3.(월) ~ 22.1.7.(금)) 
  인공지능과 기계학습 소개
  기계학습과 수학 리뷰
  E2E와 선형대수
  weekly mission을 통한 실습
tags:
- 기계학습에서의 수학
- 행렬
- 벡터
- 텐서
- 놈(norm)
- 추론
- 훈련
- 역행렬
- 정부호 행렬
- 준정부호 행렬
- 고윳값
- 고유벡터
- 고유분해
- 특이값 분해(SVD)
- 확률
- 통계
- 조건부 확률
- 베이즈 정리
- 최대 우도
- 분산
- 표준편차
- 공분산
- 가우시안 분포
- 정보이론
- 자기 정보
- 엔트로피
- 교차 엔트로피
- KL 발산
- 매개변수 공간
- 최적화
- 경사하강법
- 집단(무리)(batch) 경사 하강 알고리즘
- 확률론적 경사 하강 알고리즘(SGD)
- 딥 러닝 하드웨어
- CPU
- GPU
- TPU
- 딥 러닝 소프트웨어
- PyTorch
- TensorFlow

use_math: True
---
# 26일차(기계학습과 수학)

6주차(22.1.10.(월) ~ 22.1.17.(금)): 인공지능과 기계학습 소개
* 인공지능과 기계학습 소개
* 기계학습과 수학 리뷰
* E2E와 선형 대수
* weekly mission을 통한 실습

### 기계학습에서 수학의 역할
- 수학은 목적함수를 정의, 목적함수의 최저점을 찾아주는 최적화 이론 제공
- 최적화 이론에 학습률, 멈춤조건과 같은 제어를 추가하여 알고리즘 구축
- 사람은 알고리즘을 설계하고 데이터를 수집

### 벡터
- 샘플을 특징 벡터로 표현
- 벡터를 요소의 종류와 크기를 표현하고, 데이터 집합의 여러 개 특징 벡터를 첨자로 구분
- 4개의 특징이 각각 5.1, 3.5, 1.4, 0.2인 샘플<br>
$ x = \begin{bmatrix}x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = \begin{bmatrix}5.1 \\ 3.5 \\ 1.4 \\ 0.2 \end{bmatrix}$<br>
- 4 x 4 사진을 벡터화하면 16개의 요소를 가지는 벡터

### 행렬
- 여러 개의 벡터를 담음
- 요소 $x_{ij}$는 i번째 행, j번째 열요소
- 훈련집합을 담은 행렬을 설계행렬이라 부름
- 행: 데이터 샘플, 열: 샘플의 요소
- 행렬을 이용하면 방정식(방정식계)를 간결하게 표현 가능
- 특수행렬: 정사각행렬(정방행렬), 대각행렬, 단위행렬, 대칭행렬

### 벡터와 행렬
- 벡터와 행렬의 내적은 유사도 측정
- 심층 학습에서 계산의 결과가 예측한 결과와 내적을 하여 유사도 측정, 유사도에 따라서 매개변수 값을 변경
- 벡터와 행렬의 곱셈은 선형변환
- 어떤 공간에서 기저가 다른 공간으로의 변환

### 텐서
- 3차원 이상의 구조를 가진 숫자 배열
- 0차: 스칼라 / 1차: 벡터 / 2차: 행렬 / 3차 ... 텐서

### 놈(norm)
- 벡터의 p-norm<br>
$\lVert x \rVert_p = \displaystyle\sum_{i=1,d}{\left\vert x_i \right\vert}^{\frac{1}{p}}$<br>
- max-norm<br>
$\lVert x \rVert_{\infty} = max(\left\vert x_1 \right\vert x_2, \cdots, \left\vert x_d \right\vert)$<br>
- 2차원 공간에서 1-norm의 값이 같은 점들을 다 이었을 때 마름모 형태<br>
  2-norm의 값이 같은 점들을 다 이었을 때에는 원의 형태
  max_norm으로 갈 수록 정사각형에 가까워지는 형태
- 행렬의 프로베니우스 놈(Frobenius-norm): 행렬의 크기를 측정<br>
$\lVert A \rVert_F = \left( \displaystyle\sum_{i=1,n} \displaystyle\sum_{j=1,m} a_{ij} \right)^{\frac{1}{2}}$<br>

### 추론과 훈련
- 추론: 학습을 마친 알고리즘을 현장의 새로운 데이터에 적용하는 작업
- 훈련: 훈련집합의 샘플에 대해 식을 가장 잘 만족하는 가중치를 찾아내는 작업
- 현대 기계 학습에서 심층학습은 퍼셉트론을 여러 층으로 확장하여 만듦

### 역행렬
- 정의: $AA^{-1} = A^{-1}A = I$
- 역행렬 존재 유무 판단 조건<br>
  - $det(A) = 0$ 역행렬 없음
  - $det(A) \ne  0$ 역행렬 존재
- 기하학적 의미: 행렬식은 주어진 행렬의 곱에 의한 공간의 확장 또는 축소 해석<br>
  - $det(A) = 0$일 때 하나의 차원을 따라 축소되어 부피를 잃게 됨
  - $det(A) = 1$일 때 부피 유지한 변환/방향 보존됨
  - $det(A) = -1$일 때 부피 유지한 변환/방향 보존 안됨
  - $det(A) = 5$일 때 부피가 5배 확장되며 방향 보존됨

### 양의 정부호 행렬
- 0이 아닌 모든 벡터 $x$에 대해 $x^TAx>0$(조건에 따라 양, 음의 준정부호 행렬, 음의 정부호 행렬로 나뉨)
- 성질<br>
  - 고유값 모두 양수
  - 역행렬도 정부호 행렬
  - $det(A) \ne 0$ 역행렬 존재

### 고윳값과 고유 벡터
- $Av = \lambda v$를 만족할 때 고유 벡터는 $v$ 고윳값은 $\lambda$가 됨
- 고윳값과 고유 벡터의 기하학적 의미는 고유 벡터들을 변환 시킨 것은 고유값만큼 scaling한 결과이므로<br>
  따라서 임의의 점을 고유 벡터를 축으로 scaling한 결과

### 고유 분해
- $A = Q\Lambda Q^{-1}$
- $Q$는 $A$의 고유 벡터를 열에 배치한 행렬이고 $\Lambda$는 고윳값을 대각선에 배치한 대각행렬
- 고유 분해는 고유값과 해당 고유 벡터가 존재하는 정사각행렬에만 적용이 가능
- 그러나 기계학습에서는 **정사각행렬이 아닌 경우의 분해도 필요하므로 고유 분해는 한계**

### 특이값 분해(SVD)
- n x m 행렬 A의 특이값 분해: $ A = U \Sigma V^T $
- 왼쪽 특이행렬 $U:AA^T$의 고유 벡터를 열에 배치한 n x n 행렬
- 오른쪽 특이행렬 $V:A^T A$의 고유벡터를 열에 배치한 m x m 행렬
- $\Sigma$: $AA^T$의 고유값의 제곱근을 대각선에 배치한 n x m 행렬
- 특이값 분해는 정사각행렬이 아닌 행렬의 역행렬을 계산에 사용됨

---

### 확률과 통계
- 기계 학습이 처리할 데이터는 불확실한 세상에서 발생하므로, **불확실성**을 다루는 확률과 통계를 잘 활용해야 함

### 조건부 확률
* 어떤 사건 A가 발생했을 때 B가 발생할 확률
<center> $P(B\mid A) = \frac{P(A \cap B)}{P(A)} (단, P(A) \ne 0)$ </center>
* 주사위를 던졌는데 4이하의 수가 나왔을 때, 그 수가 짝수일 확률?
* 사건 A: 4이하의 수가 나올 확률($\frac{2}{3}$)<br>
  사건 B: 4이하의 수 중 짝수가 나올 확률($\frac{1}{3}$)<br>
  $P(B\mid A) = \frac{P(A \cap B)}{P(A)} = \frac{1}{2}$<br>
<br>
* 사건 A와 B가 독립일 경우 $P(B\mid A) = P(B)$ $\rightarrow P(B\cap A) = P(B)P(A) = P(A)P(B)$
* 예를 들어보면 주사위를 2개 던질 때 1번 주사위가 짝수일 사건, 2번 주사위가 짝수인 사건은 서로 독립

### 베이즈 정리
* 추가적인 정보에 대하여 확률을 계산할 때 주로 적용함
<center>$P(A\cap B) = P(A \mid B)P(B) = P(B\cap A) = P(B \mid A)P(A) \Leftrightarrow P(B\mid A) = \frac{P(A\mid B)P(B)}{P(A)}$</center><br>
<center>$P(A\mid B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A \cap B)}{P(A\cap B) \cup P(A^c \cap B)} = \frac{P(B \mid A)P(A)}{P(B \mid A)P(A) + P(B \mid A^c)P(A^c)}$</center><br>
* 조금 더 일반화를 해보면 사건$B = {B_1, B_2, B_3, \cdots, B_k}$가 표본 공간 S의 분할일 때
<center>$P(B_{\gamma} \mid A) = \frac{P(B_{\gamma} \cap A)}{P(A)} = \frac{P(B_{\gamma} \cap A)}{\sum_{i = 1}^{k}P(B_{i}\cap A)} = \frac{P(B_{\gamma} \mid A)P(A)}{\sum_{i=1}^{k}P(B_i)P(A\mid B_i)}$</center><br>
* 위의 식을 말로 풀어서 설명하면 사건 $A$가 발생했을 때 $B_{\gamma}$가 일어날 확률은<br>
  사건 $A$와 $B_{\gamma}$가 동시에 벌어질 확률을 사건 $A$와 $B_1, B_2, \cdots, B_k$이 공통적으로 일어날 확률들을 모두 더한 값으로 나눈 값을 뜻함
- 베이즈 정리의 해석은 **사후확률은 우도확률과 사전확률의 곱으로 해석할 수 있음**

### 확률과 우도
- 확률: 전체 데이터에서 특정한 데이터들이 발생하는 분포
- 우도: 관심있는 데이터에서 특정한 데이터들이 발생하는 분포

### 기계 학습에  베이즈 정리 적용
- 예를들어 Iris 데이터 분류 문제<br>
  - 특징 벡터 $x$, 부류 $y \in \{setosa, versicolor, virginica\}$
  - 해당 특징 벡터에 대해서 각 부류에 대한 확률(사후 확률)을 추정
  - 각 확률들에 대하여 최댓값을 가지는 확률을 선택
  - 분류 문제를 argmax로 표현하면<br>
    $\hat{y} = argmaxP(y\mid x)$<br>
<br>
- 사후확률 $P(y\mid x)$를 직접 추정하는 일은 아주 단순한 경우를 빼고 불가능
- 베이즈 정리를 이용하여 추정

### 최대우도
- 매개변수(모수)$\Theta$를 모르는 상황에서 매개변수를 추정하는 문제
- 즉, 어떤 확률변수의 관찰된 값들을 토대로 그 확률변수의 매개변수를 구하는 방법
- 관측된 데이터 집합에 대해서 해당 데이터를 발생시킬 가능성을 최대로 하는 매개변수 $\Theta$값을 찾기<br>
  최대 우도 추정: $ \widehat{\Theta} = argmaxP(\mathbb{X} \mid \Theta)$<br>
<br>
- 수치 문제를 피하기 위해 로그 표현으로 바꾸면<br>
  최대 로그우도 추정: $ \widehat{\Theta} = argmaxP(\mathbb{X} \mid \Theta) = argmax\displaystyle\sum_{i=1}^{n}log(P(x_i \mid \Theta)$<br>
  단조 증가하는 로그 함수를 이용하여 계산 단순화


### 평균과 분산
- 평균(확률 벡터 요소들의 평균): $\mu = \frac{1}{n} \displaystyle\sum_{i = 1}^{n}x_i$
- 분산(데이터가 퍼져있는 정도): $\sigma ^2 = \frac{1}{n} \displaystyle\sum_{i = 1}^{n}(x_i - \mu)^2 \rightarrow Var(f(x)) = \mathbb{E}\left[\left(f(x) - \mathbb{E}[f(x)]\right)^2\right]$
- 공분산 행렬(각 차원에 대한 상관정도): $\Sigma = \frac{1}{n} \displaystyle\sum_{i = 1}^{n}(x_i - \mu)(x_i - \mu)^T$

### 가우시안 분포
- 평균 $\mu$와 분산$\sigma ^2$으로 정의(정규분포와 비슷한 개형)<br>
  $ N(x;\mu, \sigma ^2) = \frac{1}{\sigma \sqrt{2 \pi}} exp\left(- \frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)$<br>
<br>
- 다차원의 경우 평균벡터$\boldsymbol{\mu}$와 공분산 $\Sigma$로 정의<br>
  $ N(x;\mu, \Sigma) = \frac{1}{\sqrt{\left\vert\Sigma\right\vert} \sqrt{(2 \pi)^d}} exp\left(- \frac{1}{2}(x-\boldsymbol{\mu}^T)\Sigma^{-1}(x - \boldsymbol{\mu})\right)$
  
---

### 정보이론
- 확률통계과 많은 교차점을 가짐
- 확률통계는 기계학습의 기초적인 근간 제공<br>
  - 해당 확률 분포 추정
  - 확률 분포 간의 유사성 정량화<br>
<br>
- 정보이론 관점에서도 기계학습을 접근 가능<br>
  - 불확실성을 정량화 하여 정보이론 방법을 기계학습에 활용한 예로는 **엔트로피, 교차 엔트로피, KL발산(상대 엔트로피)** ... <br>
<br>
- 사건이 지닌 정보를 정량화<br>
  - 기본 원리: 확률이 작을수록 많은 정보
  - 자주 발생하는 사건보다 잘 일어나지 않는 사건의 정보량이 많음<br>

### 자기 정보
- 사건(메시지)$e_i$의 정보량
- $h(e_i) = -log_2P(e_i)$ (이 경우에는 단위가 비트(bit), 주로 사용)
- 혹은 $-lnP(e_i)$ (이 경우에는 단위가 나츠(nat))<br>
<br>

### 엔트로피
- 확률변수 $x$의 불확실성을 나타내는 엔트로피
- 모든 사건 정보량의 기대 값으로 표현<br>
  이산 확률분포: $ H(x) = -\displaystyle\sum_{i=1, k}P(e_i)log_2P(e_i)$<br>
  연속 확률분포: $ H(x) = -\int_\mathbb{E}P(x)log_2P(x)$<br>
<br>
- 주사위(2.59)가 윷(2.03)보다 엔트로피가 높은 이유?<br>
  - 주사위는 모든 사건이 동일한 확률 $\rightarrow$ 어떤 사건이 일어날지 윷보다 **예측이 어려움**<br>
    $\rightarrow$ 주사위가 윷보다 더 **무질서하고 불확실성**이 큼 $\rightarrow$ **엔트로피가 높음** $\rightarrow$ **더 많은 비트 수로 데이터를 전송**해야 함<br>
<br>

### 교차 엔트로피
- 두 확률분포 P와 Q사이의 교차 엔트로피<br>
  $ H(P, Q) = -\displaystyle\sum_x P(x)log_2Q(x) = - \displaystyle\sum_{i=1,k}P(e_i)log_2Q(e_i)$<br>
- 심층학습의 손실함수로 많이 사용<br>
  $\rightarrow$ 분류 문제에서 출력을 확률 값을 보내고, 정답과 예측값을 비교를 해서 정량화하기 때문에 손실함수로 사용<br>
<br>
<br>
- 식을 전개하면,<br>
  $ H(P, Q) = -\displaystyle\sum_x P(x)log_2Q(x) = - \displaystyle\sum_{i=1,k}P(x)log_2Q(x) + \displaystyle\sum_{i=1,k}P(x)log_2Q(x) - \displaystyle\sum_{i=1,k}P(x)log_2Q(x)$<br>
  $\quad \quad \quad \ = H(P) + \displaystyle\sum_x P(x)log_2\frac{P(x)}{Q(x)}$<br>

- 위 전개식에서 $\displaystyle\sum_x P(x)log_2\frac{P(x)}{Q(x)}$은 **KL발산**
- 또한 $P$를 데이터의 분포라고 하면, 이는 학습과정에서 변화하지 않음($Q$값만 변동)<br>
  $\rightarrow$ 즉, 교차 엔트로피를 손실함수로 사용하는 경우, KL 발산의 최소화함과 동일
  
### KL발산
- 두 확률분포 사이의 거리를 계산할 때 주로 사용<br>
  $KL(P || Q) = \displaystyle\sum_x P(x)log_2\frac{P(x)}{Q(x)}$<br>
<br>
- 교차 엔트로피와 KL발산과의 관계는 **"P와 Q의 교차 엔트로피 = P의 엔트로피 + P와 Q 간의 KL발산"**
- **결론: 가지고 있는 데이터 분포 $P(x)$와 추정한 데이터 분포 $Q(x)$간의 차이를 최소화하는데 교차 엔트로피를 사용**

### 매개변수 공간
- 특징 공간의 높은 차원에 비해 훈련집합의 크기가 작아 참인 확률분포를 구하는 일은 불가능
- 따라서 기계 학습은 **적절한 모델(가설)을 선택, 목적함수를 정의하고, 모델의 매개변수 공간을 탐색하여 목적함수가 최저가 되는 최적점을 찾는 전략 사용**
- 특징 공간에서 해야 하는 일을 **모델의 매개변수 공간에서 하는 일로 대치**
- 따라서 기계학습이 해야 하는 일은 **손실함수를 최소로 만드는 매개변수 공간을 구하는 것**

### 최적화
- 순수 수학의 최적화: $f(x_1, x_2) = -(cos({x_1}^2) + sin({x_2}^2))^2$의 최저점을 찾아라!
- 기계 학습의 최적화: 단지 훈련집합이 주어지고, 훈련집합에 따라 정해지는 **목적함수의 최저점으로 만드는 모델의 매개변수**를 찾는 것<br>
  - 주로 SGD(확률적 경사 하강법) 사용
  - 손실함수 미분하는 과정 필요 $\rightarrow$ 오류 역전파 알고리즘<br>
- 문제 해결 알고리즘<br>
  - 낱낱탐색(exhaustive search) 알고리즘: 가능한 해를 모두 생성하고 탐색<br>
    한계: 차원이 조금만 높아져도 적용 불가능<br>
  - 무작위탐색(random search) 알고리즘: 아무 전략 없는 순진한 알고리즘(무작위로 손실함수 최대값을 설정, 해를 하나 생성하고 매개변수 탐색)
  - 경사하강법(gradient descent): **목적함수가 작아지는 방향** 구하여 매개변수 탐색<br>
<br>
- 매개값에 의해 손실함수가 정의되므로 최적화는 예측 단계가 아닌 **학습 단계**에 필요<br>
  
  
### 경사하강법
- 낮은 곳을 찾아가는 원리<br>
- $g = d\Theta = \frac{\partial{J}}{\partial{\Theta}}$(기울기)이고, $\rho$는 학습률(이동 거리 조절)<br>
  $\Theta = \Theta - \rho g$
- 함수의 기울기(경사)를 구하여 기울기가 낮은 쪽으로 반복적으로 이동하여 최소값에 도달<br>
<br>

#### 집단(무리)(batch) 경사 하강 알고리즘
- 샘플의 경사도를 구하고 평균한 후 **한꺼번에 갱신**
- 정확한 방향으로 수렴
- 훈련집합 전체를 다 봐야 갱신이 일어나므로 **학습 과정이 오래 걸림**<br>
<br>

#### 확률론적 경사 하강(SGD) 알고리즘
- 배치 경사 하강 알고리즘에서 샘플의 경사도를 구할 때 훈련집합의 무작위 일부(mini-batch)만을 보고 구함
- 수렴이 다소 헤맬 수 있음
- 따라서 한 샘플 혹은 작은 집단(무리)(mini-batch)의 경사도를 계산한 후 즉시 갱신

---

### 딥 러닝 하드웨어

- CPU: 코어수가 적고, 각각의 코어가 더 빠르고 연산력이 우수(연속적인 작업에 우수)
- GPU: 코어수가 많지만, 각각의 코어가 느린 편(병렬적인 작업에 우수), 행렬 곱셈 연산을 우수하게 처리할 수 있음
- TPU: 딥러닝 연산에 특화된 하드웨어<br>
<br>
- 데이터는 하드디스크에, 모델은 GPU에 위치
- 상호 통신 간 데이터를 GPU로 빠르게 이동시키지 못하면 병목현상이 발생하여 GPU가 동작이 느려질 수 있음
- 이를 해결하기 위해 RAM에 모든 데이터를 옮겨 놓거나, HDD대신 SSD를 사용, 여러 개의 CPU 스레드를 이용하여 병렬적으로 데이터를 이동시킴

### 딥 러닝 소프트웨어
- PyTorch<br>
  - 동적 그래프 기반으로 이루어져있기 때문에 개발하고 디버깅이 쉬움<br>
<br>
- tensorflow<br>
  - 대부분 프로젝트에서는 안전할 수 있고, 완벽하지만 거대한 커뮤니티가 있고, 연구와 상업 목적으로 이용이 가능 높은 수준의 프레임워크
  - 구글 클라우드 TPU를 이용하기 위해서 사용해야 함

### 느낀점
2주차 때 배웠던 수학의 내용이 반복된 것을 알 수 있고, 지루할 수 있지만 반복의 이유는 중요하다는 점을 잊지 말아야겠다.<br>
계속해서 또다시 반복되는 내용이 등장할 것이라고 생각하는데 그 때마다 빠르게 넘어가는 것이 아닌<br>
빈틈없이 넘어갈 수 있도록 해야할 것 같다
