---
title: 프로그래머스 인공지능 데브코스 29일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 6주차(22.1.3.(월) ~ 22.1.7.(금)) 
  인공지능과 기계학습 소개
  기계학습과 수학 리뷰
  E2E와 선형대수
  weekly mission을 통한 실습
tags:
- KNN(K-Nearest Neighbor) 알고리즘
- 분류기
- L1-norm
- L2-norm
- 교차검증

use_math: True
---
# 29일차(weekly mission)

6주차(22.1.10.(월) ~ 22.1.17.(금)): 인공지능과 기계학습 소개
* 인공지능과 기계학습 소개
* 기계학습과 수학 리뷰
* E2E와 선형 대수
* weekly mission을 통한 실습

### KNN(K-Nearest Neighbor) 알고리즘
- KNN 알고리즘은 지도학습 중 하나
- 다양한 레이블의 데이터 중에서 자신과 가까운 데이터를 k개 찾아 자신의 레이블을 결정

#### 데이터 확인

![1.png](attachment:1.png)

![2.png](attachment:2.png)

훈련 데이터 총 50000개, 32X32 픽셀에 RGB값 할당, 훈련 데이터의 레이블 50000개<br>
테스트 데이터 총 10000개<br>
<br>
클래스별 이미지 데이터 확인

![3.png](attachment:3.png)

학습시키기 전 데이터의 차원 동일하게 맞춰주기<br>
(5000, 32, 32, 3) $\rightarrow$ (5000, 32$\times$32$\times$3) = (5000, 3072)

---

#### L2 norm 구하기


```python
# k-nearest-neighbor.py
# L2 norm 구하는 로직
# 1. 2개의 반복문 사용
# 2. 1개의 반복문 사용
# 3. 반복문 사용하지 않음

def compute_distances_two_loops(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    
    for i in range(num_test):
        for j in range(num_train):
            dists[i, j] = np.linalg.norm(self.X_train[j, :] - X[i, :])
            
    return dists


def compute_distances_one_loop(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    
    for i in range(num_test):
        dists[i, :] = np.linalg.norm(X[i] - self.X_train, axis=1)
        
    return dists

def compute_distances_no_loops(self, X):
    num_test = X.shape[0]
    num_train = self.X_train.shape[0]
    dists = np.zeros((num_test, num_train))
    
    # (a - b)^2 = a^2 - 2ab + b^2
    # let a_2 := a^2, b_2 := b^2, ab := ab
    a_2 = np.square(X).sum(axis=1, keepdims=True)
    b_2 = np.square(self.X_train).sum(axis=1)
    ab = X.dot(self.X_train.T)
    dists = np.sqrt(a_2 - 2 * ab + b_2)
    
    return dists
```

![7.png](attachment:7.png)

속도 비교결과 반복문을 사용하지 않았을 때 속도가 제일 빠른 것을 확인 가능

---

#### 문제 1.

![4.png](attachment:4.png)

학습 후 테스트 데이터와 훈련 데이터 간 L2 norm을 구한 그래프<br>
- 밝은 부분은 L2 norm의 값이 큰 부분, 어두운 부분은 값이 작은 부분
- 밝게 나타난 열은 테스트 데이터가 훈련 데이터와 큰 연관이 없으며, 어두울 수록 연관성이 높아짐


---

#### 문제 2.

데이터 전처리 관련 다음과 같이 $\mu$와 $\mu_{ij}$를 정의<br>
<center>$\mu = \displaystyle\frac{1}{nhw}\displaystyle\sum_{k = 1}^{n}\displaystyle\sum_{i = 1}^{h}\displaystyle\sum_{j = 1}^{w}p_{ij}^{(k)} \quad \quad \quad \mu_{ij} = \displaystyle\frac{1}{n}\displaystyle\sum_{k = 1}^{n}p_{ij}^{(k)}$</center><br>
<br>
다음 각각의 데이터 전처리에 대해 L1-norm 분류기의 성능이 유지되는 경우는 어떤 경우인지 확인

![5.png](attachment:5.png)

![6.png](attachment:6.png)

#### 교차검증


```python
num_folds = 5
k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]

X_train_folds = []
y_train_folds = []

X_train_folds = np.array_split(X_train, num_folds)
y_train_folds = np.array_split(y_train, num_folds)

k_to_accuracies = {}


# 가능한 k값에 대해 시행
for k in k_choices:
    # 총 num_folds만큼 시행
    for i in range(num_folds):
        # 훈련 데이터와 검증 데이터 분류
        # X_train은 5000개의 데이터에 3072개 요소가 있고 3072개의 요소는 하나의 값과 대응되어야 하므로 vstack
        X_train_data = np.vstack(X_train_folds[:i] + X_train_folds[i+1:])
        # y_train은 5000개의 데이터에 label값 1개씩 있으므로 1차원으로 쭉 나열하듯이 값을 배치해야 X_train의 예측값과 대응 
        y_train_data = np.hstack(y_train_folds[:i] + y_train_folds[i+1:])
        X_val_data, y_val_data = X_train_folds[i], y_train_folds[i]
        

        # 훈련을 시행
        classifier.train(X_train_data, y_train_data)

        # 거리 구하기
        # 검증 데이터와 훈련 데이터의 L2-norm 구하기
        dists = classifier.compute_distances_no_loops(X_val_data)

        # 검증 데이터에 대해 예측
        y_pred = classifier.predict_labels(dists, k=1)

        # 정확도 계산
        num_correct = np.sum(y_pred == y_val_data)
        accuracy = float(num_correct) / len(y_val_data)
        
        # 1회 시행 후 정확도를 기록(총 num_folds만큼 시행)
        # k: [. . . . .] 형태로 기록
        k_to_accuracies[k] = k_to_accuracies.get(k, []) + [accuracy]

        
# 정확도 출력
for k in sorted(k_to_accuracies):
    for accuracy in k_to_accuracies[k]:
        print('k = %d, accuracy = %f' % (k, accuracy))
```


```python
# 테스트 데이터 예측
best_k = 1

classifier = KNearestNeighbor()
classifier.train(X_train, y_train)
y_test_pred = classifier.predict(X_test, k=best_k)


# 테스트 데이터 예측 정확도 출력
num_correct = np.sum(y_test_pred == y_test)
accuracy = float(num_correct) / num_test
print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))
```

---

#### 문제 3.
분류기 설정 중 k-NN에 대한 올바른 설명은?
1. K-NN 분류기의 결정경계는 선형으로 나타내질 것 이다. $\rightarrow$ 거짓<br>
   데이터가 산발적으로 흩어졌을 때 결정 경계가 선형으로 나타내질 수 있을 것 같아보여도<br> 
   하나의 클래스에 해당하는 데이터들이 어떤 비선형의 곡선으로 이어진 형태라면<br>
   결정 경계는 비선형일 수 있음<br>

   예를 들어 원점 $(0, 0)$ 에서 데이터의 클래스가 A이고 A를 중심으로 거리가 1인 자취에 해당하는 모든 데이터가 이어져 있고<br>
   그 데이터들의 클래스가 B라면 결정 경계는 원점을 중심으로 떨어진 거리가 0.5인 즉 반지름이 0.5인 원으로 결정 경계가 그려지므로<br>
   주어진 명제는 거짓임을 알 수 있음<br>
<br><br>
2. 1-NN에서의 훈련 오차는 5-NN에서보다 작거나 같을 것이다 $\rightarrow$ 참
3. 1-NN에서의 테스트 오차는 5-NN에서보다 작거나 같을 것이다 $\rightarrow$ 거짓
   테스트 데이터로 테스트를 진행할 때 그 중에서도 1-NN일 때에는 무조건 정확도는 100%<br>
   그 이유는 훈련된 데이터가 테스트 데이터와 완벽히 동일하기 때문<br>
   그러나 현재 데이터(클래스 A) 주변으로 4개의 데이터(클래스 B)가 있다면 5-NN일 경우에 잘못 예측을 하게 됨<br>
   따라서 현재 제일 가까운 데이터(자기자신)와 다른 클래스의 4개가 주변에 있다면 잘못 예측할 수 있는 경우가 생기게 되므로<br>
   훈련 데이터를 이용하여 테스트를 진행할 때에는 1-NN의 경우가 가장 정확도가 높다고 볼 수 있음<br>

   그러나 새로운 데이터를 가지고 테스트를 하게되면 테스트 데이터 주변 훈련 데이터의 기록에 의존하게 되고<br>
   각각의 훈련 데이터에 대응되는 값은 얼마인지 모르기 때문에 1-NN과 5-NN의 결과값은 알 수 없음<br>
<br><br>
4. 훈련 데이터 셋의 크기가 커질수록 테스트 데이터를 분류하는데 요구되는 시간이 많아질 것이다 $\rightarrow$ 참
   우선 테스트 데이터를 분류를 하는 과정을 살펴보면<br>
   하나의 테스트 데이터를 기준으로 T개의 훈련 데이터와의 L2-norm을 구하고<br>
   구한 L2-norm의 값들을 가장 작은 값 순서대로 K개를 구하기위해 정렬시킴<br>
   이 때 훈련데이터의 크기가 커지면 커질수록 당연히 테스트 데이터를 분류하는데 필요한 시간 또한 늘어날 수 밖에 없음<br>
   
---

### 느낀점
과제를 할 때보다 과제를 하기 위해 사전 세팅(예를 들면 깃 트러블, 주피터 노트북 가상환경 설정 등)할 때 애를 많이 먹었다.<br>
다행히 과제를 잘 제출했지만 깃에 관련해서는 반드시 팀 프로젝트가 시작되기 전까지는 관련된 개념을 잘 숙지하고<br>
여러가지 상황에 대해서 다른 사람들이 트러블 슈팅을 어떻게 했는지 잘 살펴봐야할 것 같다.<br>
<br>
과제를 하면서 어려운 점은 크게 없었다. 아무래도 현재 분석하려고 하는 데이터가 무엇인지, 각각의 차원이 무엇을 나타내는지 파악을 하고나니<br>
이전에 코드를 작성했던 작성자의 의도를 잘 파악할 수 있었던 것 같다.<br>
아직 모델을 훈련 시키는 코드 작성하는 것에 미숙해서 일부 코드 완성하는 구간에서 시간이 오래걸리기도 했는데<br>
2달차 학습간에는 이런 저런 트러블을 최대한 많이 겪어봐야겠다
