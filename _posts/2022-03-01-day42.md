---
title: 프로그래머스 인공지능 데브코스 42일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 9주차(22.2.7.(월) ~ 22.2.12.(토)) 
  선형회귀
  선형분류
  Weekly Mission
tags:
- 심층학습
- 표현 학습
- 깊은 다층 퍼셉트론(DMLP)
- 가중치 행렬
- DMLP의 동작
- CNN
- 합성곱(컨볼루션)
- CNN 동작
- AlexNet

use_math: True
---
# 42일차(신경망 기초 - 다층 퍼셉트론)

9주차(22.2.7.(월) ~ 22.2.12.(토)): 신경망 기초
* 신경망 기초
* 다층 퍼셉트론
* 딥러닝 기초
* monthly project
<br>
<br>

출처: 프로그래머스 인공지능 데브코스 3기 강의

### 심층학습(Deep Learning)
- 다층 퍼세브론에 은닉층을 여러개 추가하면 깊은 신경망
- 심층학습은 깊은 신경망의 학습으로 새로운 응용을 창출하고 인공지능 제품의 성능을 획기적으로 향상
- 현대 기계학습을 주도<br>

<br>
- 1980년대 깊은 신경망 아이디어 등장했으나 여러가지 한계가 있었음<br>
  - 경사 소멸(vanishing gradient) 문제
  - 작은 훈련집합
  - 완전 연결구조로 높은 복잡도
  - 과다한 연산과 시간 소요(낮은 연산의 범용 컴퓨터, 값비싼 슈퍼컴퓨터)<br>
<br>
- 일부 연구자들은 실망스러운 상황에서도 지속적인 연구<br>
  - 학습률에 따른 성능 변화 양상
  - 모멘텀과 같은 최적 탐색 방법 모색
  - 은닉 노드 수에 따른 성능 변화
  - 데이터 전처리의 영향
  - 활성함수의 영향
  - 규제 기법의 영향 등
  
#### 성공배경
- 혁신적 알고리즘 등장<br>
  - 합성곱 신경망(CNN) 구조: 부분 연결과 가중치 공유를 통해서 효율적인 신경망 학습 구조 제공
  - 경사 소멸 문제 해결을 위한 ReLU 활성함수
  - 과대적합을 방지하는데 효과적인 다양한 규제 기법
  - 층별 예비학습기법 개발
- 값싼 GPGPU의 등장
- 학습 데이터 양과 질의 향상<br>
<br>

#### 기계학습의 새로운 전환
- 전통적인 다층 퍼셉트론(고전 기계학습)<br>
  - 은닉층은 특징 추출기: 얕은 구조(제한적 특징 추출)이므로 가공하지 않은 획득한 원래 패턴을 그대로 입력하면 낮은 성능
  - 따라서 사람이 수작업 특징을 선택하거나 추출하여 신경망에 입력
- 현대 기계학습<br>
  - 학습에 의해 자동적으로 데이터로부터 특징 추출(표현 학습)
  - 특징 벡터를 신경망의 입력: 종단간 학습

---

### 표현 학습의 부각
- 깊은 신경망의 표현 학습(또는 특징 학습)<br>
  - 낮은 단계 은닉층은 선이나 모서리와 같은 간단한 (저급)특징 추출
  - 높은 단계 은닉층은 추상적인 형태의 복잡한 (고급)특징 추출<br>
<br>
- 표현 학습이 강력해짐에 따라 기존 응용에서 획기적인 성능 향상<br>
  - 영상 인식, 음성 인식, 언어 번역 등
  - 새로운 응용 창출<br>
    - 분류나 회귀 뿐 아니라 생성 모델이나 화소 수준의 영상 분할
    - CNN과 LSTM의 혼합 학습 모델(예를 들면 자연 영상에 주석 달기 응용) 등이 가능

### 깊은 다층 퍼셉트론(DMLP)의 구조
- 입력: $d + 1$차원의 특징벡터, 출력: $c$개 분류
- $L-1$개의 은닉층(입력층은 0번째 은닉층, 출력층은 $L$번째 은닉층으로 간주)<br>
  - $l$번째 은닉층의 노드 수 $n_l$로 표기<br>
<br>

![1.png](attachment:1.png)
<br>

#### 가중치 행렬
- $u_{ji}^l$은 $l-1$번째 층의 $i$번째 노드와 $l$번째 층의 $j$번째 노드를 연결하는 가중치
- $l-1$번째 층과 $l$번째 층을 연결하는 가중치는 총 $(n_{l-1} + 1)n_l$개
- 가중치 행렬을 표현하면 다음과 같음<br>
  $\mathbf{U}^{l}=\left(\begin{array}{cccc}u_{10}^{l} & u_{11}^{l} & \cdots & u_{1 n_{l-1}}^{l} \\\\\\ u_{20}^{l} & u_{21}^{l} & \cdots & u_{2 n_{l-1}}^{l} \\\\\\ \vdots & \vdots & \ddots & \vdots \\\\\\ u_{n_{l} 0}^{l} & u_{n_{l} 1}^{l} & \cdots & u_{n_{l} n_{l-1}}^{l}\end{array}\right)$ 이 때 $l = 1, 2, \cdots, L$

---

### DMLP의 동작
- MLP의 동작을 나타내는 식을 보다 많은 단계로 확장<br>
  $\mathbf{o}=\mathbf{f}(\mathbf{x})=\mathbf{f}\_{L}\left(\cdots \mathbf{f}\_{2}\left(\mathbf{f}\_{1}(\mathbf{x})\right)\right)$<br>
  $f=W_{2} \max \left(0, W_{1} x\right)$
- 학습 또한 기존 MLP 학습 유사하고 더 많은 단계(층)에 걸쳐 그레디언트 계산과 가중치 갱신을 수행

#### 전방 계산
- 입력층의 특징 벡터를 내부 표현으로 쓰면<br>
  $\mathbf{z}^{0}=\left(z_{0}, z_{1}, z_{2}, \cdots, z_{n_{0}}\right)^{\mathrm{T}}=\left(1, x_{1}, x_{2}, \cdots, x_{d}\right)^{\mathrm{T}}$
- $l$번째 층의 $j$번째 노드가 수행하는 연산<br>
  $l$번째 은닉층의 $j$번째 노드의 연산:<br>
  $z_j^l = \tau_l(s_j^l)$ 이 때 $s_j^l = \mathbf{u}\_{j}^{l} \mathbf{z}^{l-1}$<br>
  $\mathbf{z}^{l-1}=\left(1, z_{1}^{l-1}, z_{2}^{l-1}, \cdots, z_{n_{l-1}}^{l-1}\right)^{\mathrm{T}}, \quad \mathbf{u}\_{j}^{l}=\left(u_{j 0}^{l}, u\_{j 1}^{l} \cdots, u_{j n_{l-1}}^{l}\right)$<br>
<br>
- 행렬 표기를 이용하여 $l$번째 층의 연산 전체를 쓰면<br>
  $l$번째 층의 연산: $z^l = \tau_l(\mathbf{u}\_{j}^{l} \mathbf{z}^{l-1})$, $1 \le l \le L$

---

### 역사적 고찰
- 주요 알고리즘의 개선: 퍼셉트론 $\rightarrow$ 다층 퍼셉트론 $\rightarrow$ 깊은 다층 퍼셉트론
- 활성함수: 계단함수 $\rightarrow$ 시그모이드 함수 $\rightarrow$ ReLU와 변형
- 목적함수: 평균제곱 오차 $\rightarrow$ 평균제곱 오차 $\rightarrow$ 교차 엔트로피 또는 로그우도<br>
- 합성곱 신경망(CNN)의 부상

### 심층학습이 강력한 이유
- **종단간(E2E) 최적화된 학습**: 전체 깊은 신경망을 동시에 최적화
- 고전적인 방법에서는<br>
  - 분할, 특징 추출, 분류를 따로 구현한 다음 이어 붙임
  - 사람의 직관에 따르므로 성능 한계
  - 인식 대상이 달라지면 새로 설계해야 함<br>
<br>
- **깊이의 중요성**: 넓이를 넓게하는 것 보다는 깊이를 깊게하는 것이 더 정교하게 분할하는 효과
- **계층적 특징**: ImageNet으로 학습한 특징 맵 $\rightarrow$ 추출된 특징 표현
  - 깊은 신경망에서는 층의 역할이 잘 구분됨
  - 반면 얕은 신경망은 하나 또는 두 개의 은닉층이 여러 형태의 특징을 모두 담당

---

### 합성곱 신경망(CNN)
- 부분 연결 구조로 기존 DMLP의 완전 연결 구조로 인한 높은 복잡도를 해소 
- 격자 구조를 갖는 데이터에 적합
- 컨볼루션 연산을 수행하여 특징 추출
- 영상 분류나 문자 인식 등 인식문제에 높은 성능<br>
<br>

#### 컨볼루션
- 컨볼루션(Convolution): 원본 데이터의 일부와 커널에 해당하는 같은 요소끼리 곱해서 결과를 모두 더하는 선형 연산
- 보폭(Stride): 커널을 다음 컨볼루션 연산을 위해 이동시키는 칸 수
- 패딩(Padding): 컨볼루션 결과의 크기를 조정하기 위해 원본 데이터(입력) 배열의 둘레를 확장하고 0으로 채우는 연산
- 풀링(Pooling): 일정 크기의 블록을 통합하여 하나의 대표값으로 대체하는 연산
- 최대값 풀링(Max Pooling): 지정된 블록 내의 원소들 중에서 최대값을 대표값으로 선택
- 평균값 풀링(Average Pooling): 블록 내의 원소들의 평균값을 대표값으로 사용<br>
<br>

#### 구조
- 특징 추출<br>
  - 컨볼루션 연산을 하는 Conv층
  - ReLU 연산을 하는 ReLU
  - 풀링 연산을 하는 Pool<br>
<br>

- 추출된 특징을 통해 분류나 회귀를 수행하는 다층 퍼셉트론
  - 전체 연결된(Fully connected) FC층을 반복
  - 분류의 경우 마지막 층에 소프트맥스(Softmax) 연산 수행

---

### AlexNet
- 2012년에 개최된 ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 대회의 우승을 차지한 컨볼루션 신경망(CNN) 구조
- CNN의 부흥에 아주 큰 역할을 한 구조

#### Alexnet의 구조
- 2개의 GPU로 병렬연산을 수행하기 위해서 **병렬적인 구조로 설계**
- 8개의 레이어로 구성(5개의 컨볼루션 레이어와 3개의 full-connected 레이어)<br>
<br>

- 두번째, 네번째, 다섯번째 컨볼루션 레이어들은 전 단계의 같은 채널의 특징맵들과만 연결
- 세번째 컨볼루션 레이어는 전 단계의 두 채널의 특징맵들과 모두 연결
- 약 6천만 개의 가중치가 학습(기존 LeNet의 경우 6만 개)<br>
<br>
- 과적합(over-fitting)을 막기 위해서 규제 기술의 일종인 dropout을 사용
- fully-connected layer의 뉴런 중 일부를 생략(0으로 값을 바꿔버림)하면서 학습을 진행(해당 뉴런은 순전파와 역전파에 영향을 미치지 않음)
- dropout은 훈련시에 적용되는 것이고, 테스트시에는 모든 뉴런을 사용

![2.png](attachment:2.png)

### AlexNet_model 실습


```python
import torch
import torch.nn as nn

# from .utils import load_state_dict_from_url
try:
    from torch.hub import load_state_dict_from_url
except ImportError:
    from torch.utils.model_zoo import load_url as load_state_dict_from_url

from typing import Any


__all__ = ['AlexNet', 'alexnet']

model_urls = {
    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4dff8aa71.pth',
}

class AlexNet(nn.Module):
    def __init__(self, num_classes: int = 1000) -> None:
        super(AlexNet, self).__init__()
        
        # 특징 추출 부분
        self.features = nn.Sequential(
            # Conv1
            # 입력 채널: 3, 출력 채널: 64, 커널 크기: 11, 보폭: 4, 패딩 2
            nn.Conv2d(3, 64, kernel_size=11, stride=4, paddding=2),
            # 연산 결과를 기존 데이터에 반영
            nn.ReLU(inplace=True),
            # Max Pool1
            nn.MaxPool2d(kernel_size=3, stride=2),

            # Conv2
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            # Max Pool2
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv3
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv4
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv5
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Max Pool3
            nn.MaxPool2d(kernel_size=3, stride=2)
        )
        
        # 분류 부분
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            # 드롭 아웃
            nn.Dropout(),
            # 완전 연결층 생성(입력 차원: 256 * 6 * 6, 출력 차원: 4096)
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            # 출력할 때에는 클래스 개수를 맞춰줘야 함
            nn.Linear(4096, num_classes),
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # 특징 추출 부분
        # 입력 이미지 x에 대해 추출된 특징이 x에 저장
        x = self.features(x)
        x = self.avgpool(x)
        # 격자 모양의 값들을 한 줄로 나열
        x = torch.flatten(x, 1)
        
        # 분류 부분
        x = self.classifier(x)
        return x
    

# 사전학습된 모델을 가져올지 인자로 True, False로 결정
def alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> AlexNet:
    model = AlexNet(**kwargs)
    if pretrained:
        state_dict = load_state_dict_from_url(model_urls['alexnet'], progress = progress)
        model.load_state_dict(state_dict)
    return model
```

---

### 느낀점
본격적으로 딥 러닝을 시작하게 되었다. 이전에 기본적인 것들을 잘 쌓았던 것을 잘 조합하여 어려운 내용이 나올 때<br>
다양한 방면에서 생각하고 수식으로 잘 표현해서 이해를 하고 어려움을 헤쳐나가야할 것 같다.<br>
또한 코딩같은 경우에는 기존에 사용하지 않은 문법들이 종종 등장하게 되는데<br>
생소한 부분이 나와도 어렵지 않게 이해하기 위해서 틈틈히 python 문법 또한 공부를 해나가야할 것 같다
