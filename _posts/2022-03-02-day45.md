---
title: 프로그래머스 인공지능 데브코스 45일차
layout: post
post-image: https://user-images.githubusercontent.com/83870423/148743292-e6a1b86d-95ca-4f30-b96a-482104d72319.png
description: 10주차(22.2.14.(월) ~ 22.2.18.(토)) 
  선형회귀
  선형분류
  Weekly Mission
tags:
- 심층 학습(Deep Learning)
- Alexnet
- VGGNet
- GoogLeNet
- NIN 구조
- 보조 분류기
- ResNet
- 지름길 연결(skip connection)
- ImageNet
- ILSVRC
- 생성모델
- GAN

use_math: True
---
# 45일차(신경망 기초 - Deep Learning 기초)

10주차(22.2.14.(월) ~ 22.2.18.(금)): CNN & RNN
* Deep Learning 기초
* CNN Models
* Deep Learning 최적화
* RNN
* weekly mission

출처: 프로그래머스 인공지능 데브코스 3기 강의

### CNN 신경망 사례연구
- AlexNet
- VGGNet
- GoogLeNet
- ResNet

### 영상분류: 과거에는 매우 어렵고 도전적
- ImageNet: 22,000여 부류에 대해 부류별로 수백 ~ 수만장의 사진을 인터넷에서 수집하여 1,500만 장의 사진을 구축하고 공개<br>
<br>
- ILSVRC: CVPR 학술대회에서 개최하는 대회로 이미지 시각화 분류 인식 대회<br>
- 1000가지 부류에 대해 분류, 검출, 위치 지정 문제
- 120만 장의 훈련집합, 5만 장의 검증집합, 15만 장의 테스트집합
- 우승한 모델은 코드와 학습된 가중치를 공개하여 널리 사용되는 표준 신경망으로 채택

### AlexNet
#### 구조
- 컨볼루션층 5개와 완전연결(Fully Connected)층 3개
- 8개 층에 290,400 - 186,624 - 64,896 - 43,264 - 4,096 - 4,096 - 1,000 노드 배치
- 컨볼루션층은 200만개, FC층은 6500만개 가량의 매개변수
- FC층에 30배 많은 매개변수 $\rightarrow$ **향후 CNN은 FC층의 매개변수를 줄이는 방향으로 발전**<br>
![1.png](attachment:1.png)
- 당시 GPU의 메모리 크기 제한으로 인해 GPU#1, GPU#2으로 분할하여 학습 수행
- 3번째 컨볼루션 층은 GPU#1과 GPU#2의 결과를 함께 사용(GPU#1: 색과 관련되지 않은 특징 추출, GPU#2: 색과 관련된 특징 추출)
- 컨볼루션 층 큰 보폭으로 다운샘플링

#### 성공한 요인
##### 외적요인
- ImageNet이라는 대규모 사진 데이터
- GPU를 사용한 병렬처리

##### 내적 요인
- 활성함수로 ReLU사용
- 지역 반응 정규화 기법 적용<br>
  - 인간 신경망 측면억제 모방, ReLU 활성화 규제
  - 1번째, 3번재 최대 풀링 전 적용
- 과대적합 방지하기 위해 여러 규제 기법 적용<br>
  - 데이터 확대(잘라내기와 반전으로 2048배 확대)
  - 드롭아웃(완전결층에서 사용)
- 테스트 단계에서 앙상블 적용<br>
  - 입력된 영상을 잘라내기와 반전을 통해 데이터의 수를 증가하고<br>
    증가된 영상들의 예측 평균으로 최종 인식
  - 2~3% 만큼 오류율 감소 효과
  
---

### VGGNet
#### 핵심 아이디어
- 3 x 3 크기의 작은 커널 사용
- 신경망을 더욱깊게 만듦(신경망의 깊이가 어떤 영향을 주는지 확인)
- 컨볼루션층을 8 ~ 16개를 두어 AlexNet의 5개에 비해 2 ~ 3배 깊어짐

#### 구조
- 16층짜리 VGG-16 (CONV 13층 + FC 3층)
![2.png](attachment:2.png)<br>

#### 작은 커널의 이점
- GoogLeNet의 인셉션 모듈처럼 이후 깊은 신경망 구조에 영향
- 큰 크기의 커널은 여러 개의 작은 크기 커널로 분해 가능
- 매개변수의 수는 줄면서 신경망은 깊어지는 효과<br>
  5 x 5 입력에 5 x 5 커널을 적용하게되면 매개변수의 개수는 25개<br>
  3 x 3 커널을 적용하게되면 매개변수의 개수는 9 + 9 = 18개(커널 내부 원소의 수 x 입력에 대해 커널이 적용되는 횟수)<br>
  즉, 3 x 3 영역에 대해 컨볼루션 계산이 이루어지기 위해 9개의 가중치 필요<br>
  계산된 컨볼루션 값에 대해서도 9개의 가중치 필요, 총 18개 가중치 필요
- n x n 커널은 1 x n 혹은 n x 1 커널로 분해될 수 있으며, n이 클수록 매개변수의 수는 줄어드는 효과가 큼<br>
<br>

#### 1 x 1 커널
- 신경망 속의 신경망(NIN)에서 유래
- 차원을 통합하고 차원을 축소하는 효과로 인해 연산량이 감소
- m x n의 특징 맵 8개에 1 x 1 커널을 4개 적용하게 되면 m x n 특징 맵 4개가 출력<br>
  따라서 8개의 특징 맵이 4개의 특징맵으로 축소됨<br>
  ![3.png](attachment:3.png)
  
---

### GoogLeNet
#### 핵심 아이디어
- 인셉션 모듈: 수용장의 다양한 특징을 추출하기 위해 NIN의 구조를 확장하여 복수의 병렬적인 컨볼루션 층을 가짐
- 마이크로 네트워크로 MLPConv 대신 네 종류의 컨볼루션 연산을 사용하여 다양한 특징을 추출
- 1 x 1 컨볼루션을 사용하여 차원 축소((매개변수의 수 = 특징 맵의 수)를 줄임 + 깊은 신경망)
- 3 x 3, 5 x 5 같은 다양한 크기의 컨볼루션을 통해 다양한 특징들을 추출

#### NIN 구조
- 기존 컨볼루션 연산을 MLPConv 연산으로 대체
- 커널 대신 비선형 함수를 활성함수를 포함하는 MLP를 사용하여 특징 추출에 유리(FC를 적용함으로써 추출한 패치에 대해 여러가지 경로가 생성)<br>
<br>
- 신경망의 미소 신경망이 주어진 수용장의 특징을 추상화 시도<br>
<br>
- 전역 평균 풀링 사용
- MLPConv가 부류 수만큼 특징 맵을 생성하면, 특징 맵 각각을 평균하여 출력 노드에 입력
- 특징 맵에서 출력 노드까지 VGG 모델의 경우 FC로 인해 매개변수가 많았던 반면,<br>
  NIN에서는 특징 맵 전역에 대해 평균 풀링을 진행하기 때문에 매개변수가 필요하지 않음
![4.png](attachment:4.png)

#### GoogLeNet의 구조
- 인셉션 모듈을 9개 결합한 구조<br>
  - 1 x 1, 3 x 3, 5 x 5 컨볼루션, 3 x 3 Max Pooling을 통한 특징맵 추합
  - 1 x 1 컨볼루션을 통한 차원 축소
- 매개변수가 있는 층 22개, 없는 층(풀링) 5개로 총 27개 층
- 완전 연결층은 1개에 불과
- 백만 개의 매개변수를 가지며, VGGNet의 완전 연결층에 비하면 1%에 불과<br>
![5.png](attachment:5.png)

#### 보조 분류기
- 원 분류기의 오류 역전파 결과와 보조 분류기의 오류 역전파 결과를 결합하여 경사 소멸 문제 완화
- 학습할 때 도우미 역할, 추론할 때 제거<br>
<br>


### GoogLeNet 구현

<br><br>

---

<br>

### ResNet
- 잔류(잔차) 학습이라는 개념을 적용: 모듈 단위로, 부분 학습
- 성능 저하를 피하면서 층수를 대폭 늘림
- 잔류 학습은 지름길이 연결된 $\mathbf{x}$를 더한 $\mathbf{F(x) + x}$에 $\boldsymbol{\tau}$를 적용, $\mathbf{F(x)}$는 잔류(잔차)<br>
  $\mathbf{y} = \boldsymbol{\tau}(\mathbf{F}(\mathbf{x}) + \mathbf{x})$<br>
![6.png](attachment:6.png)<br>
<br>

#### 지름길 연결을 두는 이유
- 깊은 신경망 최적화<br>
  - 단순 학습의 관점의 변화를 통한 신경망 구조 변화
  - 단순 구조의 변경으로 매개변수 수에 영향 없음
  - 덧셈 연산만 증가하므로 전체 연산량 증가도 미비
- 깊어진 신경망으로 인해 정확도 개선 가능
- 경사 소멸 문제 해결<br>
$\displaystyle \frac{\partial \mathcal{E}}{\partial \mathbf{x}\_{l}}=\frac{\partial \mathcal{E}}{\partial \mathbf{x}\_{L}} \frac{\partial \mathbf{x}\_{L}}{\partial \mathbf{x}\_{l}}=\frac{\partial \mathcal{E}}{\partial \mathbf{x}\_{L}}\left(1+\frac{\partial}{\partial \mathbf{x}\_{l}} \sum_{i=l}^{L-1} \mathbf{F}\left(\mathbf{x}\_{i}\right)\right)$에서 $\displaystyle\frac{\partial}{\partial \mathbf{x}\_{l}} \sum_{i=l}^{L-1} \mathbf{F}\left(\mathbf{x}\_{i}\right)$ 이 -1이 될 가능성이 거의 없기 때문<br>

---

### 생성모델
- 주어진 데이터에 대해 값을 예측하는 것: 분별 모델 $\rightarrow P(y \mid \mathbf{x})$
- 생성모델은 주어진 레이블 값이 주어질 때 데이터 분포가 어떻게 되는지<br>
  혹은, 데이터 자체의 분포는 어떻게 되는지, 혹은 결합 확률분포가 어떻게 되는지를 추정<br>
  $P(\mathbf{x}), P(\mathbf{x} \mid y), P(\mathbf{x}, y)$를 추정<br>
<br>
- 현실에 내재한 데이터 발생 분포$P_{data}(\mathbf{x})$는 알아낼 수 없음
- 따라서 데이터 분포를 모방하는 모델의 확률 분포$P_{model}(\mathbf{x};\Theta)$를 암시적으로 표현

### GAN의 원리
- 생성기 G와 분별기 D의 대립구도<br>
  - G는 가짜 샘플 생성(위조지폐범)
  - D는 가짜와 진짜를 구별(경찰)
- GAN의 목표는 G가 만들어내는 샘플을 D가 구별하지 못하는 수준까지 학습<br>
  즉, 위조지폐범이 완벽한 위조지폐를 만들어 경찰이 구분못하는 수준까지 학습

### 느낀점
이전 실습에서 구현했던 Alexnet, VGGNet뿐만 아니라 GoogLeNet, ResNet에 대해 알아보았다.<br>
추가적으로 생성모델과 GAN에 대해 대략적으로 알게되었는데 흥미로운 부분인 것 같다.<br>
실습간에는 GoogLeNet을 구현했는데 확실히 많이 복잡했다.<br>
2014년 ILSVRC에서 우승한 모델이지만 VGGNet이 더 각광받은 이유를 알 수 있을 것 같다..(많이 복잡하긴 하다)<br>
코드를 전부 명세하긴 했지만 실제로 이해하는 부분은 일부분이었다.<br>
그럼에도 불구하고 전부를 명세한 이유는 나중에 내가 트러블 슈팅을 할 때 좋은 참고자료가 될 수 있을 것 같다.<br>
전반적으로 인셉션 과정 보조분류기 과정을 비롯하여 모델이 학습하는 과정을 다시 톺아보며 개념과 코드를 일치해가는 과정을 반복해야할 것 같다
